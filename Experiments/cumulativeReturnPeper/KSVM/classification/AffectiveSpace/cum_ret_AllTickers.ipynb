{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/simone/Desktop/NLFF/Experiments/cumulativeReturnPeper')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from math import sqrt\n",
    "import seaborn as sns; sns.set()\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "\n",
    "from technicalSignals import Indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers=['AAPL','AMZN','GOOGL','MSFT','FB','INTC','CSCO','CMCSA','NVDA','NFLX']\n",
    "\n",
    "TREND_WINDOWs = [(-48,0),(-35,0),(-28,0),(-7,0),(-1,0),(1,2),(1,8),(1,29),(1,36),(1,50)]\n",
    "kind_of_dataset = 'AffectiveSpace'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetManager:\n",
    "    def __init__(self):\n",
    "        X_raw = None\n",
    "        Y_raw = None\n",
    "        Y = None\n",
    "        X = None\n",
    "        cum_ret_test = None\n",
    "    \n",
    "    def load_dataset(self, ticker, kind, technicalFeatures=False):\n",
    "        types = {'Summary': '/home/simone/Desktop/NLFF/intrinioDatasetUpdated/SentimentFullAggregatedHourly/',\n",
    "            'AffectiveSpace': '/home/simone/Desktop/NLFF/AffectiveSpace/Aggregated_AffectSummary_dataset/',\n",
    "            'Title': '/home/simone/Desktop/NLFF/intrinioDatasetUpdated/SentimentTitleAggregatedHourly/',\n",
    "            'Senticnet':''}\n",
    "        news =  pd.read_csv(types[kind]+ticker+'.csv')\n",
    "        price = pd.read_csv('/home/simone/Desktop/NLFF/indexes/indexes'+ticker+'.csv')\n",
    "        price = price.rename(index=str, columns={\"date\": \"DATE\"})\n",
    "        news = news.rename(index=str, columns={\"initTime\": \"DATE\"})\n",
    "        news = news.drop(['Unnamed: 0'], axis=1)\n",
    "        news['DATE'] = [datetime.strptime(row, '%Y-%m-%d %H:%M:%S') for row in news['DATE']]\n",
    "        # This datased is already GMT+0\n",
    "        price['DATE'] = [datetime.strptime(row, '%Y-%m-%d %H:%M:%S') for row in price['DATE']]\n",
    "        if(technicalFeatures):\n",
    "            price['mom_30'] = Indicators.momentum(price, 30)\n",
    "            price['mom_50'] = Indicators.momentum(price, 50)\n",
    "            price['mom_100'] = Indicators.momentum(price, 100)\n",
    "            price['mom_150'] = Indicators.momentum(price, 150)\n",
    "            price['SMA_30'] = Indicators.SMA(price, 30)\n",
    "            price['SMA_50'] = Indicators.SMA(price, 50)\n",
    "            price['SMA_100'] = Indicators.SMA(price, 100)\n",
    "            price['SMA_150'] = Indicators.SMA(price, 150)\n",
    "            price['in_BBands'] = Indicators.inBBands(price)\n",
    "            price['eccessVolumes'] = Indicators.eccessOfVolumes(price)\n",
    "\n",
    "\n",
    "        #ALLIGNMENT\n",
    "        initDate = max(news['DATE'][0], datetime(2017, 5, 22, 0, 0, 0))\n",
    "        finalDate = min(news['DATE'][len(news)-1],datetime(2018, 6, 21, 0, 0, 0))\n",
    "        news.drop(news[news.DATE > finalDate].index, inplace=True)\n",
    "        news.drop(news[news.DATE < initDate].index, inplace=True)\n",
    "        news = news.reset_index(drop=True)\n",
    "        price.drop(price[price.DATE > finalDate].index, inplace=True)\n",
    "        price.drop(price[price.DATE < initDate].index, inplace=True)\n",
    "        price = price.reset_index(drop=True)\n",
    "        assert len(price) == len(news)\n",
    "        # FEATURES\n",
    "        sentiment = news.drop(['DATE'], axis=1)\n",
    "        X = sentiment\n",
    "        for window in [5,10,15,20,30,50]:\n",
    "            temp = sentiment.rolling(window).mean()\n",
    "            temp.columns = temp.columns +'_'+str(window)\n",
    "            X = pd.concat([X, temp],axis=1)\n",
    "        if(technicalFeatures):   \n",
    "            technical_features = ['mom_30','mom_50','mom_100','mom_150',\n",
    "                      'SMA_30','SMA_50','SMA_100','SMA_150',\n",
    "                      'in_BBands', 'eccessVolumes']\n",
    "            X = pd.concat([X, price[technical_features]],axis=1)\n",
    "\n",
    "            \n",
    "        #NORMALIZATION:\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        X = np.nan_to_num(np.asarray(X, dtype=float))\n",
    "        X = np.asarray(min_max_scaler.fit_transform(X))\n",
    "        self.X_raw = X\n",
    "        self.Y_raw = price\n",
    "\n",
    "    def get_dataset_for_trend(self, init, finish, perc_train = 0.7):\n",
    "        y = list()\n",
    "        x = list()\n",
    "        dates = list()\n",
    "        price = self.Y_raw\n",
    "        self.cum_ret_test = []\n",
    "        for i in range(abs(init),len(price)-finish):\n",
    "            cumulative_return =  (price.iloc[i+finish]['open']-price.iloc[i+init]['open'])/price.iloc[i+init]['open']\n",
    "            y.append(0 if cumulative_return<0 else 1)\n",
    "            dates.append(price.iloc[i]['DATE'])\n",
    "            x.append(self.X_raw[i])\n",
    "            self.cum_ret_test.append(cumulative_return)\n",
    "        \n",
    "       #y = self.normalize(np.array(y))\n",
    "        y = np.array(y)\n",
    "        x = np.array(x)\n",
    "        self.X = x\n",
    "        self.Y = y\n",
    "        nt=math.ceil(len(x)*perc_train)\n",
    "        x_tv = x[:nt]\n",
    "        y_tv = y[:nt]\n",
    "        x_test = x[nt:]\n",
    "        y_test = y[nt:]\n",
    "        self.cum_ret_test = self.cum_ret_test[nt:]\n",
    "        dates_test = dates[nt:]\n",
    "        return (x_tv,y_tv),(x_test,y_test),dates_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(tick, init, finish): (best_c, best_gamma)\n",
    "model_selection_values = {('AAPL', -48, 0): (221.22162910704503, 3.039195382313195e-05), ('AAPL', -35, 0): (2.592943797404667, 0.004520353656360245), ('AAPL', -28, 0): (385.6620421163472, 1.7433288221999873e-05), ('AAPL', -7, 0): (2.592943797404667, 0.007880462815669913), ('AAPL', -1, 0): (10826.36733874054, 5.2983169062837125e-05), ('AAPL', 1, 2): (0.017433288221999882, 0.07278953843983153), ('AAPL', 1, 8): (672.3357536499335, 3.039195382313195e-05), ('AAPL', 1, 29): (13.738237958832638, 0.22122162910704501), ('AAPL', 1, 36): (41.753189365604044, 3.039195382313195e-05), ('AAPL', 1, 50): (0.01, 0.04175318936560404), ('AMZN', -48, 0): (126.89610031679234, 0.0002807216203941176), ('AMZN', -35, 0): (126.89610031679234, 9.236708571873866e-05), ('AMZN', -28, 0): (72.78953843983153, 3.039195382313195e-05), ('AMZN', -7, 0): (0.16102620275609392, 0.04175318936560404), ('AMZN', -1, 0): (672.3357536499335, 0.12689610031679235), ('AMZN', 1, 2): (0.05298316906283707, 0.22122162910704501), ('AMZN', 1, 8): (0.01, 0.38566204211634725), ('AMZN', 1, 29): (2.592943797404667, 0.0014873521072935117), ('AMZN', 1, 36): (0.05298316906283707, 0.12689610031679235), ('AMZN', 1, 50): (2.592943797404667, 0.0014873521072935117), ('GOOGL', -48, 0): (13.738237958832638, 0.0002807216203941176), ('GOOGL', -35, 0): (0.09236708571873865, 0.04175318936560404), ('GOOGL', -28, 0): (221.22162910704503, 3.039195382313195e-05), ('GOOGL', -7, 0): (0.05298316906283707, 0.07278953843983153), ('GOOGL', -1, 0): (10826.36733874054, 5.2983169062837125e-05), ('GOOGL', 1, 2): (3562.2478902624443, 1.7433288221999873e-05), ('GOOGL', 1, 8): (0.4893900918477494, 0.013738237958832637), ('GOOGL', 1, 29): (3562.2478902624443, 1e-05), ('GOOGL', 1, 36): (10826.36733874054, 9.236708571873866e-05), ('GOOGL', 1, 50): (2043.3597178569437, 0.12689610031679235), ('MSFT', -48, 0): (0.09236708571873865, 0.013738237958832637), ('MSFT', -35, 0): (0.017433288221999882, 0.013738237958832637), ('MSFT', -28, 0): (672.3357536499335, 1.7433288221999873e-05), ('MSFT', -7, 0): (0.2807216203941177, 0.07278953843983153), ('MSFT', -1, 0): (2.592943797404667, 0.22122162910704501), ('MSFT', 1, 2): (0.09236708571873865, 0.04175318936560404), ('MSFT', 1, 8): (1172.1022975334818, 1.7433288221999873e-05), ('MSFT', 1, 29): (0.09236708571873865, 0.12689610031679235), ('MSFT', 1, 36): (0.09236708571873865, 0.12689610031679235), ('MSFT', 1, 50): (0.09236708571873865, 0.12689610031679235), ('FB', -48, 0): (0.05298316906283707, 0.013738237958832637), ('FB', -35, 0): (1172.1022975334818, 1e-05), ('FB', -28, 0): (4.520353656360245, 0.0014873521072935117), ('FB', -7, 0): (126.89610031679234, 0.002592943797404667), ('FB', -1, 0): (7.880462815669913, 0.002592943797404667), ('FB', 1, 2): (72.78953843983153, 0.0002807216203941176), ('FB', 1, 8): (2043.3597178569437, 0.0014873521072935117), ('FB', 1, 29): (385.6620421163472, 0.004520353656360245), ('FB', 1, 36): (72.78953843983153, 3.039195382313195e-05), ('FB', 1, 50): (672.3357536499335, 1.7433288221999873e-05), ('INTC', -48, 0): (0.2807216203941177, 0.013738237958832637), ('INTC', -35, 0): (126.89610031679234, 1.7433288221999873e-05), ('INTC', -28, 0): (7.880462815669913, 0.0002807216203941176), ('INTC', -7, 0): (126.89610031679234, 0.007880462815669913), ('INTC', -1, 0): (4.520353656360245, 0.02395026619987486), ('INTC', 1, 2): (23.95026619987486, 0.0002807216203941176), ('INTC', 1, 8): (4.520353656360245, 0.07278953843983153), ('INTC', 1, 29): (385.6620421163472, 0.0004893900918477494), ('INTC', 1, 36): (10826.36733874054, 0.0004893900918477494), ('INTC', 1, 50): (100000.0, 1e-05), ('CSCO', -48, 0): (126.89610031679234, 9.236708571873866e-05), ('CSCO', -35, 0): (2043.3597178569437, 1.7433288221999873e-05), ('CSCO', -28, 0): (10826.36733874054, 9.236708571873866e-05), ('CSCO', -7, 0): (72.78953843983153, 0.0004893900918477494), ('CSCO', -1, 0): (7.880462815669913, 0.07278953843983153), ('CSCO', 1, 2): (1172.1022975334818, 0.007880462815669913), ('CSCO', 1, 8): (6210.169418915616, 0.004520353656360245), ('CSCO', 1, 29): (0.01, 0.013738237958832637), ('CSCO', 1, 36): (0.2807216203941177, 0.12689610031679235), ('CSCO', 1, 50): (23.95026619987486, 0.07278953843983153), ('CMCSA', -48, 0): (1172.1022975334818, 0.00016102620275609394), ('CMCSA', -35, 0): (0.853167852417281, 0.02395026619987486), ('CMCSA', -28, 0): (0.4893900918477494, 0.013738237958832637), ('CMCSA', -7, 0): (385.6620421163472, 0.002592943797404667), ('CMCSA', -1, 0): (221.22162910704503, 0.0004893900918477494), ('CMCSA', 1, 2): (0.09236708571873865, 0.013738237958832637), ('CMCSA', 1, 8): (18873.918221350996, 0.02395026619987486), ('CMCSA', 1, 29): (0.2807216203941177, 0.12689610031679235), ('CMCSA', 1, 36): (0.05298316906283707, 0.07278953843983153), ('CMCSA', 1, 50): (2.592943797404667, 0.013738237958832637), ('NVDA', -48, 0): (18873.918221350996, 1e-05), ('NVDA', -35, 0): (7.880462815669913, 0.0002807216203941176), ('NVDA', -28, 0): (672.3357536499335, 5.2983169062837125e-05), ('NVDA', -7, 0): (1172.1022975334818, 9.236708571873866e-05), ('NVDA', -1, 0): (221.22162910704503, 0.0008531678524172815), ('NVDA', 1, 2): (18873.918221350996, 0.0002807216203941176), ('NVDA', 1, 8): (0.16102620275609392, 0.22122162910704501), ('NVDA', 1, 29): (385.6620421163472, 0.0002807216203941176), ('NVDA', 1, 36): (72.78953843983153, 0.007880462815669913), ('NVDA', 1, 50): (0.01, 0.07278953843983153), ('NFLX', -48, 0): (0.09236708571873865, 0.04175318936560404), ('NFLX', -35, 0): (7.880462815669913, 0.0004893900918477494), ('NFLX', -28, 0): (126.89610031679234, 5.2983169062837125e-05), ('NFLX', -7, 0): (1172.1022975334818, 0.0002807216203941176), ('NFLX', -1, 0): (6210.169418915616, 5.2983169062837125e-05), ('NFLX', 1, 2): (57361.52510448681, 0.22122162910704501), ('NFLX', 1, 8): (385.6620421163472, 0.007880462815669913), ('NFLX', 1, 29): (672.3357536499335, 1e-05), ('NFLX', 1, 36): (13.738237958832638, 0.0002807216203941176), ('NFLX', 1, 50): (221.22162910704503, 0.07278953843983153)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(x_tv,y_tv):\n",
    "    best_mcc = -float(np.inf)\n",
    "    best_c = 0\n",
    "    best_g = 0\n",
    "    for c in np.logspace(-2,5,30):\n",
    "        for g in np.logspace(-5,2,30):\n",
    "            print('.', end='')\n",
    "            trainpoint=math.floor(len(x_tv)*0.50)\n",
    "            dimval=math.floor(trainpoint*0.25)\n",
    "            endval=trainpoint+dimval\n",
    "            #Cross validation\n",
    "            cvMCC = 0\n",
    "            for i in range(0,4):\n",
    "                x_train=x_tv[0:trainpoint]\n",
    "                y_train=y_tv[0:trainpoint]\n",
    "                x_val=x_tv[trainpoint:endval]\n",
    "                y_val=y_tv[trainpoint:endval]\n",
    "                trainpoint=trainpoint+dimval\n",
    "                endval=endval+dimval\n",
    "                if ((sum(y_val)+6<len(x_val) and sum(y_val)>6)):\n",
    "                    x_train,y_train=smote(x_train,y_train)\n",
    "                    x_val,y_val=smote(x_val,y_val)\n",
    "                svm_model = svm.SVC(kernel='rbf', C=c, gamma=g)\n",
    "                svm_model.fit(x_train,y_train)\n",
    "                y_pred = svm_model.predict(x_val)\n",
    "                confmatrix = confusion_matrix(y_val, y_pred)\n",
    "                tn, fp, fn, tp = confmatrix.ravel()\n",
    "                denom = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "                mcc = 0 if denom== 0 else (tp*tn -fp*fn)/sqrt(denom)\n",
    "                cvMCC += mcc/4\n",
    "\n",
    "            if(cvMCC > best_mcc):\n",
    "                best_mcc = cvMCC\n",
    "                best_c = c\n",
    "                best_g = g\n",
    "    return (best_c,best_g)\n",
    "\n",
    "def smote(x,y):\n",
    "    X_resampled, y_resampled = SMOTE().fit_sample(x, y)\n",
    "    #print('check',sum(y_resampled)/len(y_resampled))\n",
    "    return X_resampled,y_resampled\n",
    "\n",
    "def sign(vec):\n",
    "    return [1 if v>0 else 0 for v in vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "==================== AAPL ==================== \n",
      "\n",
      "\n",
      "\n",
      "2018-02-23 19:00:00\n",
      "trend:  -48   0\n",
      "Best C:  221.22162910704503  best gamma:  3.039195382313195e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trend:  -35   0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-149abf9cfa05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinish\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTREND_WINDOWs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trend: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mx_tv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdates_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset_for_trend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinish\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-0f81b83ecf97>\u001b[0m in \u001b[0;36mget_dataset_for_trend\u001b[0;34m(self, init, finish, perc_train)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcum_ret_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mcumulative_return\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'open'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'open'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'open'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcumulative_return\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DATE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2102\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_loc\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   2605\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2606\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2607\u001b[0;31m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2608\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2609\u001b[0m                     \u001b[0;31m# a location index by definition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    505\u001b[0m                                  \"with size {size}\".format(key=key,\n\u001b[1;32m    506\u001b[0m                                                            size=len(self)))\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ACCs_avg = np.zeros([len(TREND_WINDOWs), 5])\n",
    "MCCs_avg = np.zeros([len(TREND_WINDOWs), 5])\n",
    "conf_matr_avg = np.zeros([2,2])\n",
    "\n",
    "\n",
    "for ticker in tickers:\n",
    "    print('\\n\\n\\n==================== '+str(ticker)+' ==================== \\n\\n\\n')\n",
    "    ds = DatasetManager()\n",
    "    ds.load_dataset(ticker = ticker, kind = kind_of_dataset,technicalFeatures=True)\n",
    "\n",
    "    for (init, finish) in TREND_WINDOWs:\n",
    "        print('trend: ',init,' ',finish)\n",
    "        (x_tv,y_tv),(x_test,y_test),dates_test = ds.get_dataset_for_trend(init, finish)\n",
    "        \n",
    "        \n",
    "        if(ticker, init, finish) in model_selection_values:\n",
    "            (best_c,best_g) = model_selection_values[(ticker, init, finish)]\n",
    "        else:\n",
    "            (best_c,best_g) = cv(x_tv,y_tv)\n",
    "            model_selection_values[(ticker, init, finish)] = (best_c,best_g)\n",
    "\n",
    "        print('Best C: ',best_c,' best gamma: ',best_g)\n",
    "        svm_model = svm.SVC(kernel='rbf', C=best_c, gamma=best_g)\n",
    "        (x_tv,y_tv) = smote(x_tv,y_tv)\n",
    "        svm_model.fit(x_tv,y_tv)\n",
    "        acc = svm_model.score(x_test,y_test)\n",
    "        y_pred = svm_model.decision_function(x_test)\n",
    "        np.savetxt('test_predictions/'+ticker+'_'+str(init)+'_'+str(finish)+'.csv', y_pred, delimiter=\",\")\n",
    "        \n",
    "        thresholds = np.linspace(0, max(np.absolute(y_pred)), num=6)[:-1]\n",
    "        for t in range(0,5):\n",
    "            threshold = thresholds[t]\n",
    "            y_over_th = []\n",
    "            y_pred_over_th = []\n",
    "            weights_over_th = []\n",
    "            for y, y_p in zip(y_test, y_pred):\n",
    "                if(abs(y_p)> threshold):\n",
    "                    y_over_th.append(y)\n",
    "                    y_pred_over_th.append(y_p)\n",
    "            mcc = matthews_corrcoef(sign(y_over_th), sign(y_pred_over_th))\n",
    "            acc = accuracy_score(sign(y_over_th), sign(y_pred_over_th))\n",
    "            ACCs_avg[TREND_WINDOWs.index((init, finish)), t]+= acc/len(tickers)\n",
    "            MCCs_avg[TREND_WINDOWs.index((init, finish)), t]+= mcc/len(tickers)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(MCCs_avg,'--r', label='MCC')\n",
    "plt.plot(ACCs_avg,'r', label='ACC')\n",
    "plt.xlabel('timewindows')\n",
    "plt.xticks(range(0,len(TREND_WINDOWs)), TREND_WINDOWs)\n",
    "plt.title('AVERAGE VALUES, '+str(kind_of_dataset)+' dataset')\n",
    "plt.legend()\n",
    "plt.show() \n",
    "print(model_selection_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions Percentile on fluctuations\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "def sign(vec):\n",
    "    return [1 if v>0 else 0 for v in vec]\n",
    "\n",
    "FUTURE_WINDOWs = [(1,2),(1,8),(1,29),(1,36),(1,50)]\n",
    "NMSEs_avg = np.zeros([len(FUTURE_WINDOWs), 5])\n",
    "ACCs_avg = np.zeros([len(FUTURE_WINDOWs), 5])\n",
    "MSEs_avg = np.zeros([len(FUTURE_WINDOWs), 5])\n",
    "MCCs_avg = np.zeros([len(FUTURE_WINDOWs), 5])\n",
    "MSEs_avg_weight = np.zeros([len(FUTURE_WINDOWs), 5])\n",
    "\n",
    "for ticker in tickers:\n",
    "    for (init, finish) in FUTURE_WINDOWs:\n",
    "        print(ticker,' ',init,' ',finish)\n",
    "        ds = DatasetManager()\n",
    "        ds.load_dataset(ticker = ticker, kind = kind_of_dataset, technicalFeatures=True)\n",
    "        (x_tv,y_tv),(x_test,y_test),dates_test = ds.get_dataset_for_trend(init, finish, perc_train = 0.7)\n",
    "        y_pred = np.loadtxt('test_predictions/'+ticker+'_'+str(init)+'_'+str(finish)+'.csv', delimiter=\",\")\n",
    "        y_test = ds.cum_ret_test\n",
    "        thresholds = np.linspace(0, max(np.absolute(y_test)), num=6)[:-1]\n",
    "        for t in range(0,5):\n",
    "            threshold = thresholds[t]\n",
    "            y_over_th = []\n",
    "            y_pred_over_th = []\n",
    "            for y, y_p in zip(y_test, y_pred):\n",
    "                if(abs(y)> threshold):\n",
    "                    y_over_th.append(y)\n",
    "                    y_pred_over_th.append(y_p)\n",
    "            nmse =  MSE(y_over_th,y_pred_over_th) / MSE(y_over_th,[0]*len(y_over_th))\n",
    "            mcc = matthews_corrcoef(sign(y_over_th), sign(y_pred_over_th))\n",
    "            acc = accuracy_score(sign(y_over_th), sign(y_pred_over_th))\n",
    "            NMSEs_avg[FUTURE_WINDOWs.index((init, finish)), t]+= nmse/len(tickers)\n",
    "            ACCs_avg[FUTURE_WINDOWs.index((init, finish)), t]+= acc/len(tickers)\n",
    "            MCCs_avg[FUTURE_WINDOWs.index((init, finish)), t]+= mcc/len(tickers)\n",
    "\n",
    "labels = [0,0.2,.4,.6,.8]\n",
    "plt.figure(figsize=(20,8))\n",
    "for i in range(len(FUTURE_WINDOWs)):\n",
    "    plt.plot(ACCs_avg[i,:], label='ACC_'+str(FUTURE_WINDOWs[i][0])+'_'+str(FUTURE_WINDOWs[i][1]))\n",
    "plt.xlabel('Percentile')\n",
    "plt.xticks(range(0,len(labels)), labels)\n",
    "plt.title('AVERAGE VALUES ACC, '+str(kind_of_dataset)+' dataset')\n",
    "plt.legend()\n",
    "plt.show() \n",
    "plt.figure(figsize=(20,8))\n",
    "for i in range(len(FUTURE_WINDOWs)):\n",
    "    plt.plot(MCCs_avg[i,:], label='MCC_'+str(FUTURE_WINDOWs[i][0])+'_'+str(FUTURE_WINDOWs[i][1]))\n",
    "plt.xlabel('Percentile')\n",
    "plt.xticks(range(0,len(labels)), labels)\n",
    "plt.title('AVERAGE VALUES MCC, '+str(kind_of_dataset)+' dataset')\n",
    "plt.legend()\n",
    "plt.show() \n",
    "for i in range(len(FUTURE_WINDOWs)):\n",
    "    plt.figure(figsize=(20,8)) \n",
    "    plt.plot(NMSEs_avg[i,:], label='NMSE_'+str(FUTURE_WINDOWs[i][0])+'_'+str(FUTURE_WINDOWs[i][1]))\n",
    "    plt.xlabel('Percentile')\n",
    "    plt.xticks(range(0,len(labels)), labels)\n",
    "    plt.title('AVERAGE VALUES Normalized MSE (NMSE), '+str(kind_of_dataset)+' dataset')\n",
    "    plt.legend()\n",
    "    plt.show() \n",
    "\n",
    "np.savetxt('NMSE_percentile_on_fluctuations.csv', NMSEs_avg, delimiter=\",\")\n",
    "np.savetxt('ACC_percentile_on_fluctuations.csv', ACCs_avg, delimiter=\",\")\n",
    "np.savetxt('MCC_percentile_on_fluctuations.csv', MCCs_avg, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions percentile on predictions\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "def sign(vec):\n",
    "    return [1 if v>0 else 0 for v in vec]\n",
    "\n",
    "FUTURE_WINDOWs = [(1,2),(1,8),(1,29),(1,36),(1,50)]\n",
    "NMSEs_avg = np.zeros([len(FUTURE_WINDOWs), 5])\n",
    "ACCs_avg = np.zeros([len(FUTURE_WINDOWs), 5])\n",
    "MSEs_avg = np.zeros([len(FUTURE_WINDOWs), 5])\n",
    "MCCs_avg = np.zeros([len(FUTURE_WINDOWs), 5])\n",
    "MSEs_avg_weight = np.zeros([len(FUTURE_WINDOWs), 5])\n",
    "\n",
    "for ticker in tickers:\n",
    "    for (init, finish) in FUTURE_WINDOWs:\n",
    "        print(ticker,' ',init,' ',finish)\n",
    "        ds = DatasetManager()\n",
    "        ds.load_dataset(ticker = ticker, kind = kind_of_dataset, technicalFeatures=True)\n",
    "        (x_tv,y_tv),(x_test,y_test),dates_test = ds.get_dataset_for_trend(init, finish, perc_train = 0.7)\n",
    "        y_pred = np.loadtxt('test_predictions/'+ticker+'_'+str(init)+'_'+str(finish)+'.csv', delimiter=\",\")\n",
    "        \n",
    "        thresholds = np.linspace(0, max(np.absolute(y_pred)), num=6)[:-1]\n",
    "        for t in range(0,5):\n",
    "            threshold = thresholds[t]\n",
    "            y_over_th = []\n",
    "            y_pred_over_th = []\n",
    "            for y, y_p in zip(y_test, y_pred):\n",
    "                if(abs(y_p)> threshold):\n",
    "                    y_over_th.append(y)\n",
    "                    y_pred_over_th.append(y_p)\n",
    "            nmse =  MSE(y_over_th,y_pred_over_th) / MSE(y_over_th,[0]*len(y_over_th))\n",
    "            mcc = matthews_corrcoef(sign(y_over_th), sign(y_pred_over_th))\n",
    "            acc = accuracy_score(sign(y_over_th), sign(y_pred_over_th))\n",
    "            NMSEs_avg[FUTURE_WINDOWs.index((init, finish)), t]+= nmse/len(tickers)\n",
    "            ACCs_avg[FUTURE_WINDOWs.index((init, finish)), t]+= acc/len(tickers)\n",
    "            MCCs_avg[FUTURE_WINDOWs.index((init, finish)), t]+= mcc/len(tickers)\n",
    "\n",
    "labels = [0,0.2,.4,.6,.8]\n",
    "plt.figure(figsize=(20,8))\n",
    "for i in range(len(FUTURE_WINDOWs)):\n",
    "    plt.plot(ACCs_avg[i,:], label='ACC_'+str(FUTURE_WINDOWs[i][0])+'_'+str(FUTURE_WINDOWs[i][1]))\n",
    "plt.xlabel('Percentile')\n",
    "plt.xticks(range(0,len(labels)), labels)\n",
    "plt.title('AVERAGE VALUES ACC, '+str(kind_of_dataset)+' dataset')\n",
    "plt.legend()\n",
    "plt.show() \n",
    "plt.figure(figsize=(20,8))\n",
    "for i in range(len(FUTURE_WINDOWs)):\n",
    "    plt.plot(MCCs_avg[i,:], label='MCC_'+str(FUTURE_WINDOWs[i][0])+'_'+str(FUTURE_WINDOWs[i][1]))\n",
    "plt.xlabel('Percentile')\n",
    "plt.xticks(range(0,len(labels)), labels)\n",
    "plt.title('AVERAGE VALUES MCC, '+str(kind_of_dataset)+' dataset')\n",
    "plt.legend()\n",
    "plt.show() \n",
    "for i in range(len(FUTURE_WINDOWs)):\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.plot(NMSEs_avg[i,:], label='NMSE_'+str(FUTURE_WINDOWs[i][0])+'_'+str(FUTURE_WINDOWs[i][1]))\n",
    "    plt.xlabel('Percentile')\n",
    "    plt.xticks(range(0,len(labels)), labels)\n",
    "    plt.title('AVERAGE VALUES Normalized MSE (NMSE), '+str(kind_of_dataset)+' dataset')\n",
    "    plt.legend()\n",
    "    plt.show() \n",
    "    \n",
    "\n",
    "np.savetxt('NMSE_percentile_on_predictions.csv', NMSEs_avg, delimiter=\",\")\n",
    "np.savetxt('ACC_percentile_on_predictions.csv', ACCs_avg, delimiter=\",\")\n",
    "np.savetxt('MCC_percentile_on_predictions.csv', MCCs_avg, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions percentile on predictions and fluctuations\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "def sign(vec):\n",
    "    return [1 if v>0 else 0 for v in vec]\n",
    "\n",
    "FUTURE_WINDOWs = [(1,2),(1,8),(1,29),(1,36),(1,50)]\n",
    "NMSEs_avg = np.zeros([len(FUTURE_WINDOWs), 4,4])\n",
    "ACCs_avg = np.zeros([len(FUTURE_WINDOWs), 4,4])\n",
    "MCCs_avg = np.zeros([len(FUTURE_WINDOWs), 4,4])\n",
    "CM_avg = np.zeros([len(FUTURE_WINDOWs), 2,2])\n",
    "\n",
    "\n",
    "\n",
    "for ticker in tickers:\n",
    "    for (init, finish) in FUTURE_WINDOWs:\n",
    "        print(ticker,' ',init,' ',finish)\n",
    "        ds = DatasetManager()\n",
    "        ds.load_dataset(ticker = ticker, kind = kind_of_dataset, technicalFeatures=True)\n",
    "        (x_tv,y_tv),(x_test,y_test),dates_test = ds.get_dataset_for_trend(init, finish, perc_train = 0.7)\n",
    "        y_pred = np.loadtxt('test_predictions/'+ticker+'_'+str(init)+'_'+str(finish)+'.csv', delimiter=\",\")\n",
    "        y_test = ds.cum_ret_test\n",
    "\n",
    "        CM_avg[FUTURE_WINDOWs.index((init, finish)), :,:] +=confusion_matrix(sign(y_test),sign(y_pred))/len(tickers)\n",
    "        threshPred = np.linspace(0, max(np.absolute(y_pred)), num=6)[:-2]\n",
    "        threshFluct = np.linspace(0, max(np.absolute(y_test)), num=6)[:-2]\n",
    "        for tP in range(0,4):\n",
    "            for tF in range(0,4):\n",
    "                threshP = threshPred[tP]\n",
    "                threshF = threshFluct[tF]\n",
    "                y_over_th = []\n",
    "                y_pred_over_th = []\n",
    "                for y, y_p in zip(y_test, y_pred):\n",
    "                    if(abs(y_p)> threshP and abs(y)> threshF):\n",
    "                        y_over_th.append(y)\n",
    "                        y_pred_over_th.append(y_p)\n",
    "                if(len(y_over_th)>0 and len(y_pred_over_th)>0):\n",
    "                    nmse =  MSE(y_over_th,y_pred_over_th) / MSE(y_over_th,[0]*len(y_over_th))\n",
    "                    mcc = matthews_corrcoef(sign(y_over_th), sign(y_pred_over_th))\n",
    "                    acc = accuracy_score(sign(y_over_th), sign(y_pred_over_th))\n",
    "                    NMSEs_avg[FUTURE_WINDOWs.index((init, finish)), tP,tF]+= nmse/len(tickers)\n",
    "                    ACCs_avg[FUTURE_WINDOWs.index((init, finish)), tP,tF]+= acc/len(tickers)\n",
    "                    MCCs_avg[FUTURE_WINDOWs.index((init, finish)), tP,tF]+= mcc/len(tickers)\n",
    "\n",
    "labels = [0,0.2,.4,.6,.8]\n",
    "for i in range(len(FUTURE_WINDOWs)):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    sns.heatmap(ACCs_avg[i,:,:],annot=True, fmt=\".2f\")\n",
    "    plt.xlabel('Percentile')\n",
    "    plt.title('ACC '+str(FUTURE_WINDOWs[i]))\n",
    "    plt.show() \n",
    "\n",
    "for i in range(len(FUTURE_WINDOWs)):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    sns.heatmap(MCCs_avg[i,:,:],annot=True, fmt=\".2f\")\n",
    "    plt.xlabel('Percentile')\n",
    "    plt.xticks(range(0,len(labels)), labels)\n",
    "    plt.title('MCC '+str(FUTURE_WINDOWs[i]))\n",
    "    plt.show() \n",
    "for i in range(len(FUTURE_WINDOWs)):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    sns.heatmap(NMSEs_avg[i,:,:],annot=True, fmt=\".2f\")    \n",
    "    plt.xlabel('Percentile')\n",
    "    plt.xticks(range(0,len(labels)), labels)\n",
    "    plt.title('NMSE '+str(FUTURE_WINDOWs[i]))\n",
    "    plt.show() \n",
    "for i in range(len(FUTURE_WINDOWs)):\n",
    "    print('Conf matr '+str(FUTURE_WINDOWs[i]))\n",
    "    print(CM_avg[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
