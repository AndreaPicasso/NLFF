{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/simone/Desktop/NLFF/Experiments/cumulativeReturnPeper')\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import math\n",
    "from math import sqrt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "from technicalSignals import Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers=['AAPL','AMZN','GOOGL','MSFT','FB','INTC','CSCO','CMCSA','NVDA','NFLX']\n",
    "\n",
    "TREND_WINDOWs = [(1,2),(1,8),(1,29),(1,36),(1,50)]\n",
    "kind_of_dataset = 'AffectiveSpace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetManager:\n",
    "    def __init__(self):\n",
    "        X_raw = None\n",
    "        Y_raw = None\n",
    "        Y = None\n",
    "        X = None\n",
    "        cum_ret_test = None\n",
    "    \n",
    "    def load_dataset(self, ticker, kind, technicalFeatures=False):\n",
    "        types = {'Summary': '/home/simone/Desktop/NLFF/intrinioDatasetUpdated/SentimentFullAggregatedHourly/',\n",
    "            'AffectiveSpace': '/home/simone/Desktop/NLFF/AffectiveSpace/Aggregated_AffectSummary_dataset/',\n",
    "            'Title': '/home/simone/Desktop/NLFF/intrinioDatasetUpdated/SentimentTitleAggregatedHourly/',\n",
    "            'Senticnet':''}\n",
    "        news =  pd.read_csv(types[kind]+ticker+'.csv')\n",
    "        price = pd.read_csv('/home/simone/Desktop/NLFF/indexes/indexes'+ticker+'.csv')\n",
    "        price = price.rename(index=str, columns={\"date\": \"DATE\"})\n",
    "        news = news.rename(index=str, columns={\"initTime\": \"DATE\"})\n",
    "        news = news.drop(['Unnamed: 0'], axis=1)\n",
    "        news['DATE'] = [datetime.strptime(row, '%Y-%m-%d %H:%M:%S') for row in news['DATE']]\n",
    "        # This datased is already GMT+0\n",
    "        price['DATE'] = [datetime.strptime(row, '%Y-%m-%d %H:%M:%S') for row in price['DATE']]\n",
    "        if(technicalFeatures):\n",
    "            price['mom_30'] = Indicators.momentum(price, 30)\n",
    "            price['mom_50'] = Indicators.momentum(price, 50)\n",
    "            price['mom_100'] = Indicators.momentum(price, 100)\n",
    "            price['mom_150'] = Indicators.momentum(price, 150)\n",
    "            price['SMA_30'] = Indicators.SMA(price, 30)\n",
    "            price['SMA_50'] = Indicators.SMA(price, 50)\n",
    "            price['SMA_100'] = Indicators.SMA(price, 100)\n",
    "            price['SMA_150'] = Indicators.SMA(price, 150)\n",
    "            price['in_BBands'] = Indicators.inBBands(price)\n",
    "            price['eccessVolumes'] = Indicators.eccessOfVolumes(price)\n",
    "\n",
    "\n",
    "        #ALLIGNMENT\n",
    "        initDate = max(news['DATE'][0], datetime(2017, 5, 22, 0, 0, 0))\n",
    "        finalDate = min(news['DATE'][len(news)-1],datetime(2018, 6, 21, 0, 0, 0))\n",
    "        news.drop(news[news.DATE > finalDate].index, inplace=True)\n",
    "        news.drop(news[news.DATE < initDate].index, inplace=True)\n",
    "        news = news.reset_index(drop=True)\n",
    "        price.drop(price[price.DATE > finalDate].index, inplace=True)\n",
    "        price.drop(price[price.DATE < initDate].index, inplace=True)\n",
    "        price = price.reset_index(drop=True)\n",
    "        assert len(price) == len(news)\n",
    "        # FEATURES\n",
    "        sentiment = news.drop(['DATE'], axis=1)\n",
    "        X = sentiment\n",
    "        for window in [5,10,15,20,30,50]:\n",
    "            temp = sentiment.rolling(window).mean()\n",
    "            temp.columns = temp.columns +'_'+str(window)\n",
    "            X = pd.concat([X, temp],axis=1)\n",
    "        if(technicalFeatures):   \n",
    "            technical_features = ['mom_30','mom_50','mom_100','mom_150',\n",
    "                      'SMA_30','SMA_50','SMA_100','SMA_150',\n",
    "                      'in_BBands', 'eccessVolumes']\n",
    "            X = pd.concat([X, price[technical_features]],axis=1)\n",
    "\n",
    "            \n",
    "        #NORMALIZATION:\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        X = np.nan_to_num(np.asarray(X, dtype=float))\n",
    "        X = np.asarray(min_max_scaler.fit_transform(X))\n",
    "        self.X_raw = X\n",
    "        self.Y_raw = price\n",
    "\n",
    "    def get_dataset_for_trend(self, init, finish, perc_train = 0.7):\n",
    "        y = list()\n",
    "        x = list()\n",
    "        dates = list()\n",
    "        price = self.Y_raw\n",
    "        self.cum_ret_test = []\n",
    "        for i in range(abs(init),len(price)-finish):\n",
    "            cumulative_return =  (price.iloc[i+finish]['open']-price.iloc[i+init]['open'])/price.iloc[i+init]['open']\n",
    "            y.append(0 if cumulative_return<0 else 1)\n",
    "            dates.append(price.iloc[i]['DATE'])\n",
    "            x.append(self.X_raw[i])\n",
    "            self.cum_ret_test.append(cumulative_return)        \n",
    "        y = np.array(y)\n",
    "        x = np.array(x)\n",
    "        self.X = x\n",
    "        self.Y = y\n",
    "        nt=math.ceil(len(x)*perc_train)\n",
    "        x_tv = x[:nt]\n",
    "        y_tv = y[:nt]\n",
    "        x_test = x[nt:]\n",
    "        y_test = y[nt:]\n",
    "        self.cum_ret_test = self.cum_ret_test[nt:]\n",
    "        dates_test = dates[nt:]\n",
    "        return (x_tv,y_tv),(x_test,y_test),dates_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "====================  trend:  1   29  ==================== \n",
      "\n",
      "\n",
      "AMZN\n",
      "2018-02-20 20:00:00 2018-02-20 20:00:00 561 561\n",
      "2018-06-14 19:00:00 2018-06-14 19:00:00\n",
      "GOOGL\n",
      "2018-02-20 20:00:00 2018-02-20 20:00:00 561 561\n",
      "2018-06-14 19:00:00 2018-06-14 19:00:00\n",
      "MSFT\n",
      "2018-02-20 20:00:00 2018-02-20 20:00:00 561 561\n",
      "2018-06-14 19:00:00 2018-06-14 19:00:00\n",
      "FB\n",
      "2018-02-20 20:00:00 2018-02-20 20:00:00 561 561\n",
      "2018-06-14 19:00:00 2018-06-14 19:00:00\n",
      "INTC\n",
      "2018-02-20 20:00:00 2018-02-20 20:00:00 561 561\n",
      "2018-06-14 19:00:00 2018-06-14 19:00:00\n",
      "CSCO\n",
      "2018-02-20 20:00:00 2018-02-20 20:00:00 561 561\n",
      "2018-06-14 19:00:00 2018-06-14 19:00:00\n",
      "CMCSA\n",
      "2018-02-20 20:00:00 2018-02-20 20:00:00 561 561\n",
      "2018-06-14 19:00:00 2018-06-14 19:00:00\n",
      "NVDA\n",
      "2018-02-20 20:00:00 2018-02-20 20:00:00 561 561\n",
      "2018-06-14 19:00:00 2018-06-14 19:00:00\n",
      "NFLX\n",
      "2018-02-20 20:00:00 2018-02-20 20:00:00 561 561\n",
      "2018-06-14 19:00:00 2018-06-14 19:00:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for (init, finish) in TREND_WINDOWs:\n",
    "    print('\\n\\n\\n====================  trend: ',init,' ',finish, ' ==================== \\n\\n')\n",
    "    predictions = pd.DataFrame()\n",
    "    for ticker in tickers:\n",
    "        ds = DatasetManager()\n",
    "        ds.load_dataset(ticker = ticker, kind = kind_of_dataset, technicalFeatures=True)\n",
    "        (x_tv,y_tv),(x_test,y_test),dates_test = ds.get_dataset_for_trend(init, finish, perc_train = 0.7)\n",
    "        y_pred = np.loadtxt(ticker+'_'+str(init)+'_'+str(finish)+'.csv', delimiter=',')\n",
    "        assert len(dates_test) == len(y_pred)\n",
    "        if(ticker == 'CSCO'): #CSCO non allineato per 1h, tolgo il primo ed inserisco un ultimo fake\n",
    "            dates_test = dates_test[1:]\n",
    "            y_pred = y_pred[1:]\n",
    "            dates_test.append(dates_test[-1]+timedelta(hours=1))\n",
    "            y_pred = np.append(y_pred, 0)\n",
    "        if not predictions.empty:\n",
    "            print(ticker)\n",
    "            print(predictions.index[0],dates_test[0],len(predictions.index),len(dates_test))\n",
    "            print(predictions.index[-1],dates_test[-1])\n",
    "            assert list(predictions.index) == dates_test\n",
    "        predictions[ticker] = y_pred\n",
    "        predictions.index = dates_test\n",
    "    predictions.to_csv('AllTickers_'+str(init)+'_'+str(finish)+'.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
