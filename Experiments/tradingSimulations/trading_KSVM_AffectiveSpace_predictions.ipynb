{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import backtrader as bt\n",
    "#import matplotlib.pyplot as plt\n",
    "import backtrader.indicators as btind\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from math import sqrt\n",
    "from technicalSignals import momentum,SMA,inBBands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers=['AAPL','AMZN','GOOGL','MSFT','FB','INTC','CSCO','CMCSA','NVDA','NFLX']\n",
    "TREND_WINDOWs = [(-48,0),(-35,0),(-28,0),(-7,0),(-1,0),(1,2),(1,8),(1,29),(1,36),(1,50)]\n",
    "TREND_WINDOWs = [(1,36)]\n",

    "kind_of_dataset = 'AffectiveSpace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetManager:\n",
    "    def __init__(self):\n",
    "        X_raw = None\n",
    "        Y_raw = None\n",
    "        Y = None\n",
    "        X = None\n",
    "    \n",
    "    def load_dataset(self, ticker, kind, technicalFeatures=False):\n",
    "        types = {'Summary': '/home/andrea/Desktop/NLFF/intrinioDatasetUpdated/SentimentFullAggregatedHourly/',\n",
    "            'AffectiveSpace': '/home/andrea/Desktop/NLFF/AffectiveSpace/Aggregated_AffectSummary_dataset/',\n",
    "            'Title': '/home/andrea/Desktop/NLFF/intrinioDatasetUpdated/SentimentTitleAggregatedHourly/',\n",
    "            'Senticnet':''}\n",
    "        news =  pd.read_csv(types[kind]+ticker+'.csv')\n",
    "        price = pd.read_csv('/home/andrea/Desktop/NLFF/indexes/indexes'+ticker+'.csv')\n",
    "        price = price.rename(index=str, columns={\"date\": \"DATE\"})\n",
    "        news = news.rename(index=str, columns={\"initTime\": \"DATE\"})\n",
    "        news = news.drop(['Unnamed: 0'], axis=1)\n",
    "        news['DATE'] = [datetime.strptime(row, '%Y-%m-%d %H:%M:%S') for row in news['DATE']]\n",
    "        # This datased is already GMT+0\n",
    "        price['DATE'] = [datetime.strptime(row, '%Y-%m-%d %H:%M:%S') for row in price['DATE']]\n",
    "        if(technicalFeatures):\n",
    "            price['mom_30'] = momentum(price, 30)\n",
    "            price['mom_50'] = momentum(price, 50)\n",
    "            price['mom_100'] = momentum(price, 100)\n",
    "            price['mom_150'] = momentum(price, 150)\n",
    "            price['SMA_30'] = SMA(price, 30)\n",
    "            price['SMA_50'] = SMA(price, 50)\n",
    "            price['SMA_100'] = SMA(price, 100)\n",
    "            price['SMA_150'] = SMA(price, 150)\n",
    "            price['in_BBands'] = inBBands(price)\n",
    "\n",
    "        #ALLIGNMENT\n",
    "        initDate = max(news['DATE'][0], datetime(2017, 5, 22, 0, 0, 0))\n",
    "        finalDate = min(news['DATE'][len(news)-1],datetime(2018, 6, 20, 0, 0, 0))\n",
    "        news.drop(news[news.DATE > finalDate].index, inplace=True)\n",
    "        news.drop(news[news.DATE < initDate].index, inplace=True)\n",
    "        news = news.reset_index(drop=True)\n",
    "        price.drop(price[price.DATE > finalDate].index, inplace=True)\n",
    "        price.drop(price[price.DATE < initDate].index, inplace=True)\n",
    "        price = price.reset_index(drop=True)\n",
    "        assert len(price) == len(news)\n",
    "        # FEATURES\n",
    "        sentiment = news.drop(['DATE'], axis=1)\n",
    "        X = sentiment\n",
    "        for window in [5,10,15,20,30,50]:\n",
    "            temp = sentiment.rolling(window).mean()\n",
    "            temp.columns = temp.columns +'_'+str(window)\n",
    "            X = pd.concat([X, temp],axis=1)\n",
    "        if(technicalFeatures):   \n",
    "            technical_features = ['mom_30','mom_50','mom_100','mom_150','SMA_30','SMA_50','SMA_100','SMA_150','in_BBands']\n",
    "            X = pd.concat([X, price[technical_features]],axis=1)\n",
    "\n",
    "            \n",
    "        #NORMALIZATION:\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        X = np.nan_to_num(np.asarray(X, dtype=float))\n",
    "        X = np.asarray(min_max_scaler.fit_transform(X))\n",
    "        self.X_raw = X\n",
    "        self.Y_raw = price\n",
    "\n",
    "    def get_dataset_for_trend(self, init, finish, perc_train = 0.7):\n",
    "        y = list()\n",
    "        x = list()\n",
    "        dates = list()\n",
    "        price = self.Y_raw\n",
    "        for i in range(abs(init),len(price)-finish):\n",
    "            cumulative_return =  (price.iloc[i+finish]['open']-price.iloc[i+init]['open'])/price.iloc[i+init]['open']\n",
    "            s =np.sign(cumulative_return)\n",
    "            y.append(0 if s==-1 else 1)\n",
    "            dates.append(price.iloc[i]['DATE'])\n",
    "            x.append(self.X_raw[i])\n",
    "\n",
    "        y = np.array(y)\n",
    "        x = np.array(x)\n",
    "        self.X = x\n",
    "        self.Y = y\n",
    "        nt=math.ceil(len(x)*perc_train)\n",
    "        x_tv = x[:nt]\n",
    "        y_tv = y[:nt]\n",
    "        x_test = x[nt:]\n",
    "        y_test = y[nt:]\n",
    "        dates_test = dates[nt:]\n",
    "        return (x_tv,y_tv),(x_test,y_test),dates_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(x_tv,y_tv):\n",
    "    best_mcc = -float(np.inf)\n",
    "    best_c = 0\n",
    "    best_g = 0\n",
    "    for c in np.logspace(-3,4,10):\n",
    "        for g in np.logspace(-3,4,10):\n",
    "            print('.', end='')\n",
    "            trainpoint=math.floor(len(x_tv)*0.50)\n",
    "            dimval=math.floor(trainpoint*0.25)\n",
    "            endval=trainpoint+dimval\n",
    "            #Cross validation\n",
    "            cvMCC = 0\n",
    "            for i in range(0,4):\n",
    "                x_train=x_tv[0:trainpoint]\n",
    "                y_train=y_tv[0:trainpoint]\n",
    "                x_val=x_tv[trainpoint:endval]\n",
    "                y_val=y_tv[trainpoint:endval]\n",
    "                trainpoint=trainpoint+dimval\n",
    "                endval=endval+dimval\n",
    "                svm_model = svm.SVC(kernel='rbf', C=c, gamma=g)\n",
    "                svm_model.fit(x_train,y_train)\n",
    "                y_pred = svm_model.predict(x_val)\n",
    "                confmatrix = confusion_matrix(y_val, y_pred)\n",
    "                tn, fp, fn, tp = confmatrix.ravel()\n",
    "                denom = (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)\n",
    "                mcc = 0 if denom== 0 else (tp*tn -fp*fn)/sqrt(denom)\n",
    "                cvMCC += mcc/6\n",
    "\n",
    "            if(cvMCC > best_mcc):\n",
    "                best_mcc = cvMCC\n",
    "                best_c = c\n",
    "                best_g = g\n",
    "    return (best_c,best_g)\n",
    "\n",
    "# def normalize2(values):\n",
    "#     pos_val = []\n",
    "#     for v in values:\n",
    "#         if v>0:\n",
    "#             pos_val.append(v)\n",
    "#     m = min(pos_val)\n",
    "#     M = max(pos_val)\n",
    "#     pos_val(pos_val-m)/(M-m)\n",
    "#     neg_val = []\n",
    "#     for v in values:\n",
    "#         if v<=0:\n",
    "#             neg_val.append(-v)\n",
    "#     m = min(neg_val)\n",
    "#     M = max(neg_val)\n",
    "#     neg_val(neg_val-m)/(M-m)\n",
    "#     p = 0\n",
    "#     n = 0\n",
    "#     for i in \n",
    "def normalize(values):\n",
    "    m = min(values)\n",
    "    M = max(values)\n",
    "    values = 2*(values-m)/(M-m)-1\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "====================  trend:  1   36  ==================== \n",
      "\n",
      "\n",
      "\n",
      "AAPL\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DatasetManager' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-475e88b4fd41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mticker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtickers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkind_of_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtechnicalFeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mx_tv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdates_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset_for_trend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinish\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DatasetManager' is not defined"
     ]
    }
   ],
   "source": [
    "# ========== MAKE PREDICTIONS FILE ====================\n",
    "\n",
    "for (init, finish) in TREND_WINDOWs:\n",
    "    print('\\n\\n\\n====================  trend: ',init,' ',finish, ' ==================== \\n\\n')\n",
    "    predictions = pd.DataFrame()\n",
    "    for ticker in tickers:\n",
    "        print('\\n'+ticker)\n",
    "        ds = DatasetManager()\n",
    "        ds.load_dataset(ticker = ticker, kind = kind_of_dataset, technicalFeatures=False)\n",
    "        (x_tv,y_tv),(x_test,y_test),dates_test = ds.get_dataset_for_trend(init, finish, perc_train = 0.7)\n",
    "        (best_c,best_g) = cv(x_tv,y_tv)\n",
    "        svm_model = svm.SVC(kernel='rbf', C=best_c, gamma=best_g)\n",
    "        svm_model.fit(x_tv,y_tv)\n",
    "        y_pred = svm_model.decision_function(x_test) #This is not the class, is the value of the prediction of the SVM\n",
    "        if not predictions.empty:\n",
    "            assert list(predictions.index) == dates_test\n",
    "        predictions[ticker] = normalize(y_pred)\n",
    "        predictions[ticker+'_not_norm'] = y_pred\n",
    "        predictions.index = dates_test\n",
    "    predictions.to_csv('testPredictions/onlyNews'+kind_of_dataset+'/AllTickers_'+str(init)+'_'+str(finish)+'.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================    Trading Library utilities\n",
    "\n",
    "    \n",
    "# class Sizer(bt.Sizer):\n",
    "#     params = dict(stake=1)\n",
    "\n",
    "#     def _getsizing(self, comminfo, cash, data, isbuy):\n",
    "#         dt, i = self.strategy.datetime.date(), data._id\n",
    "#         s = self.p.stake * (1 + (not isbuy))\n",
    "#         print('{} Data {} OType {} Sizing to {}'.format(\n",
    "#             dt, data._name, ('buy' * isbuy) or 'sell', s))\n",
    "\n",
    "#         return s\n",
    "\n",
    "    \n",
    "class Strategy(bt.Strategy):\n",
    "    params = dict(\n",
    "        pred_threshold = None,        #buy if prediction more than this threshold (prediction values normalized 1: most secure prediction)\n",
    "        num_pred_over_threshold = None, #buy if more than this number of prediction over threshold\n",
    "        forecast_window = None,\n",
    "        predictions = None,\n",
    "        verbose = None\n",
    "    )\n",
    "\n",
    "    def log(self, txt, dt=None):\n",
    "        dt = dt or self.datetime.datetime().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print('%s, %s' % (dt, txt))\n",
    "\n",
    "    def notify_order(self, order):\n",
    "        if self.verbose:\n",
    "            if order.status in [order.Submitted, order.Accepted]:\n",
    "                return\n",
    "            if order.status in [order.Completed]:\n",
    "                if order.isbuy():\n",
    "                    self.log('BUY EXECUTED, %.2f' % order.executed.price)\n",
    "                elif order.issell():\n",
    "                    self.log('SELL EXECUTED, %.2f' % order.executed.price)\n",
    "            elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n",
    "                self.log('Order Canceled/Margin/Rejected')\n",
    "\n",
    "        \n",
    "    def __init__(self):\n",
    "        self.planned_sell = {}  # PLANNED SELL FOR EACH BUY AFTER TREND WINDOW dict: selldate, stock -> amount\n",
    "        self.forecast_window = self.params.forecast_window\n",
    "        self.predictions = self.params.predictions\n",
    "        self.pred_threshold = self.params.pred_threshold\n",
    "        self.num_pred_over_threshold = self.params.num_pred_over_threshold\n",
    "        self.verbose = self.params.verbose\n",
    "\n",
    "    def next(self): \n",
    "        positions = {}\n",
    "        for i, d in enumerate(self.datas):\n",
    "            #dt = self.datetime.date()\n",
    "            dt = self.datetime.datetime().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            time_idx = np.where(self.predictions.index==dt)[0][0]\n",
    "            dn = d._name\n",
    "            #ticker_pred = self.predictions[dn].at[dt]\n",
    "            ticker_pred = self.predictions[dn+'_not_norm'].at[dt]\n",
    "            previous_pred = self.predictions[dn].iloc[time_idx-self.num_pred_over_threshold:time_idx]\n",
    "            previous_pred = sum([1 if p>self.pred_threshold else 0 for p in previous_pred]) #count prev over threshold\n",
    "            pos = self.getposition(d).size\n",
    "            positions[dn]=pos\n",
    "            # Strategy: buy if abs(pred)> threshold or if more than n predictions positive\n",
    "            if(abs(ticker_pred)>self.pred_threshold and previous_pred>=self.num_pred_over_threshold):\n",
    "                # Buy and set planned sell if prediction positive\n",
    "                if(ticker_pred > 0):\n",
    "                    self.buy(data = d, size=1)                \n",
    "                    idx_to_sell = time_idx+self.forecast_window\n",
    "                    self.planned_sell[(dn,idx_to_sell)] = 1\n",
    "                else:\n",
    "                    self.sell(data = d, size=1)                \n",
    "                    idx_to_sell = time_idx+self.forecast_window\n",
    "                    self.planned_sell[(dn,idx_to_sell)] = -1\n",
    "            #Execute sell planned for now\n",
    "            if (dn,time_idx) in self.planned_sell:\n",
    "                amount = self.planned_sell[(dn,time_idx)]\n",
    "                if(amount>0):\n",
    "                    self.sell(data = d, size=amount)\n",
    "                else:\n",
    "                    self.buy(data = d, size=amount)\n",
    "                del self.planned_sell[(dn,time_idx)] \n",
    "        if self.verbose:\n",
    "                print('{} Positions {}'.format(dt, positions))\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "def printTradeAnalysis(analyzer):\n",
    "    total_open = analyzer.total.open\n",
    "    total_closed = analyzer.total.closed\n",
    "    total_won = analyzer.won.total\n",
    "    total_lost = analyzer.lost.total\n",
    "    win_streak = analyzer.streak.won.longest\n",
    "    lose_streak = analyzer.streak.lost.longest\n",
    "    pnl_net = round(analyzer.pnl.net.total,2)\n",
    "    strike_rate = (total_won / total_closed) * 100\n",
    "    h1 = ['Total Open', 'Total Closed', 'Total Won', 'Total Lost']\n",
    "    h2 = ['Strike Rate','Win Streak', 'Losing Streak', 'PnL Net']\n",
    "    r1 = [total_open, total_closed,total_won,total_lost]\n",
    "    r2 = [strike_rate, win_streak, lose_streak, pnl_net]\n",
    "    if len(h1) > len(h2):\n",
    "        header_length = len(h1)\n",
    "    else:\n",
    "        header_length = len(h2)\n",
    "    print_list = [h1,r1,h2,r2]\n",
    "    row_format =\"{:<15}\" * (header_length + 1)\n",
    "    print(\"Trade Analysis Results:\")\n",
    "    for row in print_list:\n",
    "        print(row_format.format('',*row))\n",
    "\n",
    "def printSQN(analyzer):\n",
    "    sqn = round(analyzer.sqn,2)\n",
    "    print('SQN: {}'.format(sqn))\n"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 9,

   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================  trend:  1   36  ==================== \n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'testPredictions/onlyNewsAffectiveSpace/AllTickers_1_36.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",

      "\u001b[0;32m<ipython-input-9-398f4b690d1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcerebro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetcash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcerebro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetcommission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommission\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'testPredictions/onlyNews'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mkind_of_dataset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/AllTickers_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdates_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%Y-%m-%d %H:%M:%S'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mevenPlot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'testPredictions/onlyNewsAffectiveSpace/AllTickers_1_36.csv' does not exist"
     ]
    }
   ],
   "source": [
    "pred_threshold = 0.5       #buy if prediction more than this threshold (prediction values normalized 1: most secure prediction)\n",
    "num_pred_over_threshold = 2  #buy if more than this number of prediction over threshold\n",
    "init_value = 100000.0\n",
    "\n",
    "for (init, finish) in TREND_WINDOWs:\n",
    "    print('\\n====================  trend: ',init,' ',finish, ' ==================== \\n')\n",
    "    cerebro = bt.Cerebro(stdstats=False)\n",
    "    cerebro.addobservermulti(bt.observers.BuySell)\n",
    "    cerebro.broker.setcash(init_value)\n",
    "    cerebro.broker.setcommission(commission=0.0001)\n",
    "    predictions = pd.read_csv('testPredictions/onlyNewsSu/AllTickers_'+str(init)+'_'+str(finish)+'.csv', index_col = 0)\n",
    "    dates_test = [datetime.strptime(row, '%Y-%m-%d %H:%M:%S') for row in predictions.index]\n",
    "    evenPlot = True\n",
    "    for ticker in tickers:\n",
    "        data = bt.feeds.GenericCSVData(\n",
    "                    dataname='/home/andrea/Desktop/NLFF/indexes/indexes'+ticker+'.csv',\n",
    "                    name=ticker,\n",
    "                    timeframe = bt.TimeFrame.Minutes, \n",
    "                    compression = 60,\n",
    "                    datetime=1,open=2,high=3,low=4,close=5,volume=6,openinterest=-1,\n",
    "                    fromdate=dates_test[0],\n",
    "                    todate=dates_test[-1]+timedelta(minutes=1),\n",
    "                    reverse=False)\n",
    "#         if(evenPlot):\n",
    "#             data0 = data\n",
    "#             evenPlot = False\n",
    "#         else:\n",
    "#             data.plotinfo.plotmaster = data0\n",
    "#             evenPlot = True\n",
    "        cerebro.adddata(data)\n",
    "        \n",
    "    #cerebro.addsizer(Sizer)    \n",
    "    assert init == 1 #Up to now only future\n",
    "    cerebro.addstrategy(Strategy,\n",
    "                        pred_threshold = pred_threshold,\n",
    "                        num_pred_over_threshold = num_pred_over_threshold,\n",
    "                        forecast_window=finish,\n",
    "                        predictions = predictions,\n",
    "                        verbose = True)\n",
    "    cerebro.addanalyzer(bt.analyzers.TradeAnalyzer, _name=\"ta\")\n",
    "    cerebro.addanalyzer(bt.analyzers.SQN, _name=\"sqn\")\n",
    "    print('Starting Portfolio Value: %.2f' % init_value)\n",
    "    strategy = cerebro.run()[0]\n",
    "    final_value = cerebro.broker.getvalue()\n",
    "    printTradeAnalysis(strategy.analyzers.ta.get_analysis())\n",
    "    printSQN(strategy.analyzers.sqn.get_analysis())\n",
    "    print('Final Portfolio Value: %.2f \\nGain: %.2f' % (final_value, final_value/init_value - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cerebro.plot(volume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MARKET PERFORMANCE:\n",
    "class BuyAndHold(bt.Strategy):\n",
    "    def log(self, txt, dt=None):\n",
    "        dt = dt or self.datetime.datetime().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print('%s, %s' % (dt, txt))\n",
    "\n",
    "    def notify_order(self, order):\n",
    "        if order.status in [order.Submitted, order.Accepted]:\n",
    "            return\n",
    "        if order.status in [order.Completed]:\n",
    "            if order.isbuy():\n",
    "                self.log('BUY EXECUTED, %.2f' % order.executed.price)\n",
    "            elif order.issell():\n",
    "                self.log('SELL EXECUTED, %.2f' % order.executed.price)\n",
    "      \n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def next(self): \n",
    "        for i, d in enumerate(self.datas):\n",
    "            self.buy(data = d, size=1)                \n",
    "\n",
    "\n",
    "init_value = 3670.0 #Correct value to buy one stock a the beginning\n",
    "init_value = 100000\n",
    "\n",
    "for (init, finish) in TREND_WINDOWs:\n",
    "    print('\\n====================  trend: ',init,' ',finish, ' ==================== \\n')\n",
    "    cerebro = bt.Cerebro()\n",
    "    cerebro.broker.setcash(init_value)\n",
    "    cerebro.broker.setcommission(commission=0.0001)\n",
    "    predictions = pd.read_csv('testPredictions/AllTickers_'+str(init)+'_'+str(finish)+'.csv', index_col = 0)\n",
    "    dates_test = [datetime.strptime(row, '%Y-%m-%d %H:%M:%S') for row in predictions.index]\n",
    "    for ticker in tickers:\n",
    "        data = bt.feeds.GenericCSVData(\n",
    "                    dataname='/home/andrea/Desktop/NLFF/indexes/indexes'+ticker+'.csv',\n",
    "                    name=ticker,\n",
    "                    timeframe = bt.TimeFrame.Minutes, \n",
    "                    compression = 60,\n",
    "                    datetime=1,open=2,high=3,low=4,close=5,volume=6,openinterest=-1,\n",
    "                    fromdate=dates_test[0],\n",
    "                    todate=dates_test[-1]+timedelta(minutes=1),\n",
    "                    reverse=False)\n",
    "        cerebro.adddata(data)\n",
    "        \n",
    "    cerebro.addstrategy(BuyAndHold)\n",
    "    cerebro.addanalyzer(bt.analyzers.SQN, _name=\"sqn\")\n",
    "    print('Starting Portfolio Value: %.2f' % init_value)\n",
    "    strategy = cerebro.run()[0]\n",
    "    final_value = cerebro.broker.getvalue()\n",
    "    print('Final Portfolio Value: %.2f \\nGain: %.2f' % (final_value, final_value/init_value - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
