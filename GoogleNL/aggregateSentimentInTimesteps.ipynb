{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import ast\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DATE', 'GoogleSentiment', 'microsoft_sa', 'stock_sa', 'compani_sa', 'share_sa', 'appl_sa', 'nasdaq_sa', 'amazon_sa', 'googl_sa', 'earn_sa', 'investor_sa', 'investorplace stock market_sa', 'market_sa', 'facebook_sa', 'posit_sa', 'world_sa', 'game_sa', 'revenu_sa', 'busi_sa', 'microsoft corpor_sa', 'amp trading tip_sa', 'cloud_sa', 'u.s._sa', 'technolog_sa', 'growth_sa', 'result_sa', 'thing_sa', 'amp_sa', 'analyst_sa', 'report_sa', 'ibm_sa', 'microsoft_se', 'stock_se', 'compani_se', 'share_se', 'appl_se', 'nasdaq_se', 'amazon_se', 'googl_se', 'earn_se', 'investor_se', 'investorplace stock market_se', 'market_se', 'facebook_se', 'posit_se', 'world_se', 'game_se', 'revenu_se', 'busi_se', 'microsoft corpor_se', 'amp trading tip_se', 'cloud_se', 'u.s._se', 'technolog_se', 'growth_se', 'result_se', 'thing_se', 'amp_se', 'analyst_se', 'report_se', 'ibm_se', 'microsoft_ma', 'stock_ma', 'compani_ma', 'share_ma', 'appl_ma', 'nasdaq_ma', 'amazon_ma', 'googl_ma', 'earn_ma', 'investor_ma', 'investorplace stock market_ma', 'market_ma', 'facebook_ma', 'posit_ma', 'world_ma', 'game_ma', 'revenu_ma', 'busi_ma', 'microsoft corpor_ma', 'amp trading tip_ma', 'cloud_ma', 'u.s._ma', 'technolog_ma', 'growth_ma', 'result_ma', 'thing_ma', 'amp_ma', 'analyst_ma', 'report_ma', 'ibm_ma', 'microsoft_co', 'stock_co', 'compani_co', 'share_co', 'appl_co', 'nasdaq_co', 'amazon_co', 'googl_co', 'earn_co', 'investor_co', 'investorplace stock market_co', 'market_co', 'facebook_co', 'posit_co', 'world_co', 'game_co', 'revenu_co', 'busi_co', 'microsoft corpor_co', 'amp trading tip_co', 'cloud_co', 'u.s._co', 'technolog_co', 'growth_co', 'result_co', 'thing_co', 'amp_co', 'analyst_co', 'report_co', 'ibm_co', 'tot_se', 'tot_ma']\n"
     ]
    }
   ],
   "source": [
    "# EXTRACT SENTIMENT AGGREGATED BY TIMESPAN\n",
    "\n",
    "ticker = 'MSFT'\n",
    "news =  pd.read_csv('/home/simone/Desktop/NLFF/GoogleNL/SentimentSingleNews/'+str(ticker)+'_googleSentVector.csv')\n",
    "news.drop_duplicates(subset=['DATE'], inplace=True)\n",
    "news = news.sort_values(by=['DATE'])\n",
    "news = news.reset_index(drop=True)\n",
    "news = news.drop(['Unnamed: 0'], axis=1)\n",
    "news['DATE'] = [datetime.strptime(row, '%Y-%m-%d %H:%M:%S ') for row in news['DATE']]\n",
    "#news['entSentVec'] = [ast.literal_eval(row) for row in news['entSentVec']]\n",
    "\n",
    "print(list(news.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stock', 'investor', 'analyst', 'amazon', 'nasdaq', 'market', 'amp', 'amp trading tip', 'investorplace stock market', 'posit', 'world', 'result', 'googl', 'microsoft corpor', 'ibm', 'earn', 'busi', 'thing', 'report', 'cloud', 'revenu', 'game', 'technolog', 'growth', 'u.s.', 'appl', 'facebook', 'microsoft', 'share', 'compani']\n",
      "2017-05-22 14:00:00\n",
      "2017-05-22 00:46:00\n",
      "Start: 2017-05-22 00:46:00(2017-05-22 14:00:00) i: 0 j: 4051\n",
      "End: 2018-06-20 23:29:41\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "timeSpan = pd.read_csv(\"/home/simone/Desktop/NLFF/indexes/indexes\"+str(ticker)+\".csv\")\n",
    "timeSpan = timeSpan['date'].tolist()\n",
    "# This dataset is already GMT+0\n",
    "timeSpan = [datetime.strptime(row, '%Y-%m-%d %H:%M:%S') for row in timeSpan]\n",
    "\n",
    "features_names = news.columns.tolist()\n",
    "features_names.remove('DATE')\n",
    "features_names.remove('GoogleSentiment')\n",
    "concepts = list(set([f[:-3] for f in features_names]))\n",
    "concepts.remove('tot')\n",
    "print(concepts)\n",
    "sentiment = pd.DataFrame(columns=['initTime']+features_names)\n",
    "#print(list(sentiment.columns))\n",
    "\n",
    "#Prendiamo intervallo massimo dove ci sono entrambi i dataset:\n",
    "#massimo della data iniziale tra i due\n",
    "#minimo della data finale tra i due\n",
    "initDate = max(timeSpan[0], news['DATE'][0])\n",
    "finalDate = min(timeSpan[len(timeSpan)-1], news['DATE'][len(news)-1])\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "# ALLINEAMENTO INIZIO\n",
    "while(timeSpan[j] < initDate):\n",
    "    j+=1\n",
    "init = j\n",
    "while(news['DATE'][i] <= initDate - timedelta(hours=1)):\n",
    "    i+=1\n",
    "\n",
    "print(timeSpan[j])\n",
    "print(news['DATE'][i])\n",
    "    \n",
    "print(\"Start: \"+str(initDate) +\"(\"+str(timeSpan[j])+\") i: \"+str(i)+\" j: \"+str(j))\n",
    "print(\"End: \"+str(finalDate))\n",
    "\n",
    "#ALLINEAMENTO FINE DENTRO I WHILE\n",
    "while( news['DATE'][i] < finalDate and timeSpan[j] < finalDate ):\n",
    "    initTime = timeSpan[j]\n",
    "    normal_sum = {feature_name: 0 for feature_name in features_names}    \n",
    "    num_tot_news = 0\n",
    "    while(i<len(news)-1 and timeSpan[j] > news['DATE'][i]):\n",
    "        if(i%1000 == 0):\n",
    "            print(i)\n",
    "        if not (timeSpan[j] > news['DATE'][i] and timeSpan[j-1] <= news['DATE'][i]):\n",
    "            print(\"timeSpan[\"+str(j)+\"]: \"+str(timeSpan[j])+\" news[\"+str(i)+\"] : \" +str(news['DATE'][i]) + \" timeSpan[\"+str(j-1)+\"]: \"+str(timeSpan[j-1]))\n",
    "            assert False\n",
    "#         a = news['entSentVec'][i]\n",
    "#         print(type(a))\n",
    "#         print(len(a))\n",
    "#         a = np.asarray(news['entSentVec'][i])\n",
    "#         print(type(a))\n",
    "#         print(a.shape)\n",
    "            \n",
    "        normal_sum = {f : normal_sum[f]+news[f][i] for f in features_names}        \n",
    "        num_tot_news +=1\n",
    "        i+=1\n",
    "    j+=1\n",
    "    #sentiment.loc[j] = {'initTime':initTime, 'num_news':num_tot_news}\n",
    "    sentiment.loc[j,'initTime'] = initTime\n",
    "    sentiment.loc[j,'tot_co'] = num_tot_news\n",
    "      \n",
    "    for c in concepts:\n",
    "        normal_sum[c+'_sa'] /= normal_sum[c+'_co'] if normal_sum[c+'_co'] > 0 else 1\n",
    "        normal_sum[c+'_se'] /= normal_sum[c+'_co'] if normal_sum[c+'_co'] > 0 else 1\n",
    "        normal_sum[c+'_ma'] /= normal_sum[c+'_co'] if normal_sum[c+'_co'] > 0 else 1\n",
    "    for f in normal_sum.keys():\n",
    "        sentiment.loc[j,f] = normal_sum[f]\n",
    "    \n",
    "\n",
    "\n",
    "end = j\n",
    "if(len(sentiment) != end - init):\n",
    "    print(len(sentiment))\n",
    "    print(end - init + 1)\n",
    "    assert False\n",
    "\n",
    "\n",
    "#sentiment.to_csv('Aggregated_1h_dataset/'+str(ticker)+'_googleSentPerTimestep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initTime</th>\n",
       "      <th>microsoft_sa</th>\n",
       "      <th>stock_sa</th>\n",
       "      <th>compani_sa</th>\n",
       "      <th>share_sa</th>\n",
       "      <th>appl_sa</th>\n",
       "      <th>nasdaq_sa</th>\n",
       "      <th>amazon_sa</th>\n",
       "      <th>googl_sa</th>\n",
       "      <th>earn_sa</th>\n",
       "      <th>...</th>\n",
       "      <th>growth_co</th>\n",
       "      <th>result_co</th>\n",
       "      <th>thing_co</th>\n",
       "      <th>amp_co</th>\n",
       "      <th>analyst_co</th>\n",
       "      <th>report_co</th>\n",
       "      <th>ibm_co</th>\n",
       "      <th>tot_se</th>\n",
       "      <th>tot_ma</th>\n",
       "      <th>tot_co</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-05-22 14:00:00</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-05-22 15:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-05-22 16:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-05-22 17:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-05-22 18:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              initTime microsoft_sa  stock_sa  compani_sa  share_sa  appl_sa  \\\n",
       "0  2017-05-22 14:00:00        0.125       0.0         0.0       0.0      0.0   \n",
       "1  2017-05-22 15:00:00            0       0.0         0.0       0.0      0.0   \n",
       "2  2017-05-22 16:00:00            0       0.0         0.0       0.0      0.0   \n",
       "3  2017-05-22 17:00:00            0       0.0         0.0       0.0      0.0   \n",
       "4  2017-05-22 18:00:00            0       0.0         0.0       0.0      0.0   \n",
       "\n",
       "   nasdaq_sa  amazon_sa  googl_sa  earn_sa   ...    growth_co  result_co  \\\n",
       "0        0.0        0.0       0.0      0.0   ...          0.0        0.0   \n",
       "1        0.0        0.0       0.0      0.0   ...          0.0        0.0   \n",
       "2        0.0        0.0       0.1      0.0   ...          0.0        0.0   \n",
       "3        0.0        0.0       0.0      0.0   ...          0.0        0.0   \n",
       "4        0.0        0.0       0.0      0.0   ...          0.0        0.0   \n",
       "\n",
       "   thing_co  amp_co  analyst_co  report_co  ibm_co  tot_se tot_ma  tot_co  \n",
       "0       0.0     0.0         0.0        0.0     0.0     0.3    1.2     7.0  \n",
       "1       0.0     0.0         0.0        0.0     0.0       0      0     0.0  \n",
       "2       0.0     0.0         0.0        0.0     0.0     0.1    0.2     2.0  \n",
       "3       0.0     0.0         0.0        0.0     0.0       0      0     0.0  \n",
       "4       0.0     0.0         0.0        0.0     0.0       0      0     0.0  \n",
       "\n",
       "[5 rows x 124 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = sentiment.sort_values(by=['initTime'])\n",
    "sentiment = sentiment.reset_index(drop=True)\n",
    "sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment.to_csv('Aggregated_1h_dataset/'+str(ticker)+'_googleSentPerTimestep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
