{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utente\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2881: DtypeWarning: Columns (63,108,109,110,176) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAPL', 'ADBE', 'ADI', 'ADP', 'ADSK', 'AKAM', 'ALGN', 'ALXN', 'AMAT', 'AMGN', 'AMZN', 'ATVI', 'AVGO', 'BIDU', 'BIIB', 'BMRN', 'CA', 'CELG', 'CERN', 'CHTR', 'CMCSA', 'COST', 'CSCO', 'CSX', 'CTAS', 'CTRP', 'CTSH', 'CTXS', 'DISCA', 'DISH', 'DLTR', 'EA', 'EBAY', 'ESRX', 'EXPE', 'FAST', 'FB', 'FISV', 'FOXA', 'GILD', 'GOOGL', 'HAS', 'HOLX', 'HSIC', 'IDXX', 'ILMN', 'INCY', 'INTC', 'INTU', 'ISRG', 'JBHT', 'JD', 'KHC', 'KLAC', 'LBTYA', 'LRCX', 'MAR', 'MAT', 'MCHP', 'MDLZ', 'MELI', 'MNST', 'MSFT', 'MU', 'MXIM', 'MYL', 'NFLX', 'NTES', 'NVDA', 'ORLY', 'PAYX', 'PCAR', 'PCLN', 'PYPL', 'QCOM', 'REGN', 'ROST', 'SBUX', 'SHPG', 'SIRI', 'STX', 'SWKS', 'SYMC', 'TMUS', 'TSCO', 'TSLA', 'TXN', 'ULTA', 'VIAB', 'VOD', 'VRSK', 'VRTX', 'WBA', 'WYNN', 'XLNX', 'XRAY']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from stockstats import StockDataFrame \n",
    "import numpy as np\n",
    "import pysentiment as ps\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "from os import listdir\n",
    "hiv4 = ps.HIV4()\n",
    "\n",
    "INITIAL_WEIGHT = 1;\n",
    "\n",
    "\n",
    "\n",
    "indexesFiles=list()\n",
    "newsFiles=list()\n",
    "files=list()\n",
    "newsFiles=listdir(r\"C:\\Users\\Utente\\Desktop\\NLFF\\NLFF\\intrinioDataset\")\n",
    "indexesFiles=listdir(r\"C:\\Users\\Utente\\Desktop\\NLFF\\NLFF\\DataSetIndexes\")\n",
    "#print(newsFiles)\n",
    "#print(indexesFiles)\n",
    "tickers=list()\n",
    "for file in indexesFiles:\n",
    "    file=re.sub('\\.csv$', '', file)\n",
    "    file=re.sub('indexes', '', file)\n",
    "    tickers.append(file)\n",
    "print(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on AAPL...\n",
      "            Unnamed: 0      open    high      low     close   volume  \\\n",
      "0  2017-03-13 15:00:00  138.8500  139.40  138.820  139.1101  2239261   \n",
      "1  2017-03-13 16:00:00  139.1100  139.16  138.840  139.0600  2436748   \n",
      "2  2017-03-13 17:00:00  139.0587  139.09  138.860  138.9800  1456796   \n",
      "3  2017-03-13 18:00:00  138.9900  139.43  138.940  139.1100  2023389   \n",
      "4  2017-03-13 19:00:00  139.1150  139.33  139.095  139.2601  1459115   \n",
      "\n",
      "   close_12_ema  close_26_ema      macd     macds     macdh    macd.1  \\\n",
      "0    139.110100    139.110100  0.000000  0.000000  0.000000  0.000000   \n",
      "1    139.082963    139.084087 -0.001124 -0.000624 -0.000999 -0.001124   \n",
      "2    139.042776    139.046689 -0.003913 -0.001972 -0.003882 -0.003913   \n",
      "3    139.063996    139.064388 -0.000392 -0.001437  0.002090 -0.000392   \n",
      "4    139.117277    139.109775  0.007502  0.001222  0.012560  0.007502   \n",
      "\n",
      "    macds.1     boll_ub     boll_lb      rsi_6     rsi_12   vr_6_sma  \\\n",
      "0  0.000000         NaN         NaN        NaN        NaN        NaN   \n",
      "1 -0.000624  139.155902  139.014198   0.000000   0.000000   0.000000   \n",
      "2 -0.001972  139.181274  138.918793   0.000000   0.000000   0.000000   \n",
      "3 -0.001437  139.187820  138.942230  56.165617  52.967990  17.322599   \n",
      "4  0.001222  139.308374  138.899706  75.348962  71.789389  35.352708   \n",
      "\n",
      "       wr_10       wr_6  \n",
      "0  49.982759  49.982759  \n",
      "1  58.620690  58.620690  \n",
      "2  72.413793  72.413793  \n",
      "3  52.459016  52.459016  \n",
      "4  27.852459  27.852459  \n",
      "i\n",
      "9999\n",
      "lendata\n",
      "10000\n",
      "j\n",
      "0\n",
      "lentimespan\n",
      "1748\n",
      "timeSpan[996]: 2017-10-03 21:00:00 data[9999] : 2017-10-03 19:55:49 timeSpan[995]: 2017-10-03 20:00:00\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e00454650546>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtimeSpan\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtimeSpan\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"timeSpan[\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"]: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeSpan\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" data[\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"] : \"\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" timeSpan[\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"]: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeSpan\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[1;32massert\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhiv4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'summary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#tickers=[\"PCLN\"]\n",
    "\n",
    "for ticker in tickers:\n",
    "    data = list()\n",
    "    sentiment20minutes = list()\n",
    "    timeSpan = list()\n",
    "    print(\"Working on \"+ticker+\"...\")\n",
    "    \n",
    "        \n",
    "    reader=pd.read_csv(r'C:\\Users\\Utente\\Desktop\\NLFF\\NLFF\\intrinioDataset\\\\'+ticker+'.csv') #reader = csv.DictReader(csvfile)\n",
    "    for row in reader.T.iteritems():\n",
    "        time  = datetime.strptime(row[1]['PUBLICATION_DATE'], '%Y-%m-%d %H:%M:%S +%f')\n",
    "        data.append({'time':time, 'summary':row[1]['SUMMARY']}) \n",
    "\n",
    "    #with open('indexesFB.csv', 'rb') as csvfile:\n",
    "        #from time import sleep\n",
    "        #sleep(1)\n",
    "    reader = pd.read_csv(r'C:\\Users\\Utente\\Desktop\\NLFF\\NLFF\\DataSetIndexes\\indexes'+ticker+'.csv')\n",
    "    print(reader.head())\n",
    "    reader.rename(columns={'Unnamed: 0':'date'}, inplace=True)\n",
    "    #print(reader.head())\n",
    "    for row in reader.T.iteritems():\n",
    "        time  = datetime.strptime(row[1]['date'], '%Y-%m-%d %H:%M:%S')\n",
    "        timeSpan.append(time) \n",
    "\n",
    "\n",
    "\n",
    "    i = len(data)-1;\n",
    "    j=0;\n",
    "    print(\"i\")\n",
    "    print(i)\n",
    "    print(\"lendata\")\n",
    "    print(len(data))\n",
    "    print(\"j\")\n",
    "    print(j)\n",
    "    print(\"lentimespan\")\n",
    "    print(len(timeSpan))\n",
    "\n",
    "    while(timeSpan[j]< data[i]['time']):\n",
    "        j+=1\n",
    "\n",
    "    weighted_sum = 0;\n",
    "    normal_sum = 0\n",
    "    \n",
    "    while(i>0 and j<len(timeSpan)-1):\n",
    "        \n",
    "        total_subj = INITIAL_WEIGHT\n",
    "        num_sentiment = 1\n",
    "        \n",
    "        initTime = timeSpan[j]\n",
    "        j+=1\n",
    "\n",
    "\n",
    "        # if(i == len(data)-1):\n",
    "        # \tdelta =timedelta(minutes=data[i]['time'].minute % 20, seconds=data[i]['time'].second, microseconds=data[i]['time'].microsecond)\n",
    "        # \tinitTime = data[i]['time'] - delta\n",
    "        # else:\n",
    "        # \tinitTime = initTime + timedelta(minutes=20)\n",
    "\n",
    "        # if(initTime.hour >= 22 and initTime.minute>0):\n",
    "        # \tinitTime = initTime + timedelta(days=1)\n",
    "        # \tinitTime = initTime.replace(hour=15, minute=40)\n",
    "\n",
    "        # weighted_sum = 0 -> I don't reinitialize because I want to take it as a value for the next period \"interpolation\"\n",
    "        #print(\"per SIMOOOOOOO\")\n",
    "        #print(\"i\")\n",
    "        #print(i)\n",
    "        #print(\"lendata\")\n",
    "        #print(len(data))\n",
    "        #print(\"j\")\n",
    "        #print(j)\n",
    "        #print(\"lentimespan\")\n",
    "        #print(len(timeSpan))\n",
    "        while(i>0 and timeSpan[j] > data[i]['time']):\n",
    "            if not (timeSpan[j] > data[i]['time'] and timeSpan[j-1] <= data[i]['time']):\n",
    "                print(\"timeSpan[\"+str(j)+\"]: \"+str(timeSpan[j])+\" data[\"+str(i)+\"] : \" +str(data[i]['time']) + \" timeSpan[\"+str(j-1)+\"]: \"+str(timeSpan[j-1]))\n",
    "                assert False\n",
    "            try:\n",
    "                tokens = hiv4.tokenize(data[i]['summary'])\n",
    "                score = hiv4.get_score(tokens)\n",
    "                #print(score)\n",
    "                #subjec,10000)\n",
    "                #f_score=np.multiply(score['Polarity'],sub)\n",
    "                #f_score=np.multiply(f_score,0.001)\n",
    "                #sentiment=np.append(sentiment,f_score)\n",
    "        ##\n",
    "                #summary = TextBlob(data[i]['summary']).sentiment\n",
    "                polarity = score['Polarity']\n",
    "                subjectivity = score['Subjectivity']\n",
    "                normal_sum += polarity\n",
    "\n",
    "                weighted_sum += polarity*subjectivity\n",
    "                \n",
    "                total_subj+=subjectivity\n",
    "                num_sentiment +=1\n",
    "            except:\n",
    "                \n",
    "                print(\"Exception\")\n",
    "                print(data[i]['summary'])\n",
    "\n",
    "            i-=1\n",
    "        weighted_sum /=total_subj\n",
    "        normal_sum /=num_sentiment\n",
    "\n",
    "        #print('line '+str(i) +\"   \"+ str(timeSpan[j])+\"   \"+ str(data[i]['time']) +\"   \"+ str(normal_sum))\n",
    "\n",
    "\n",
    "        sentiment20minutes.append({'initTime':initTime, 'sentimentWeighted':weighted_sum, 'sentiment':normal_sum})\n",
    "\n",
    "\n",
    "    #Write results\n",
    "    with open('sentiment20minutesFB.csv', 'w') as csvfile:\n",
    "        fieldnames = ['initTime', 'sentimentWeighted', 'sentiment']\n",
    "        sentFrame = pd.DataFrame(sentiment20minutes)\n",
    "        #print(sentFrame)\n",
    "        sentFrame.to_csv(r'C:\\Users\\Utente\\Desktop\\NLFF\\NLFF\\DataSetSentiment20\\sentiment20minutes'+ticker+'.csv')\n",
    "        print(\"Finiscede with \"+ticker)\n",
    "       # for row in sentiment20minutes.T.iteritems():\n",
    "        #\twriter.writerow(row[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sentiment20minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sentiment20minutes.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(sentiment20minutes)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
