{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from datetime import datetime, timedelta\n",
    "from time import sleep\n",
    "import senticAPIextractor\n",
    "import pandas as pd\n",
    "import FilSentimentExtract \n",
    "#import matplotlib.pyplot as plt\n",
    "#from stockstats import StockDataFrame \n",
    "import numpy as np\n",
    "#import pysentiment as ps\n",
    "#from collections import OrderedDict\n",
    "import re\n",
    "import senticAPIextractor\n",
    "from os import listdir\n",
    "import random\n",
    "\n",
    "\n",
    "INITIAL_WEIGHT = 1;\n",
    "\n",
    "\n",
    "\n",
    "indexesFiles=list()\n",
    "newsFiles=list()\n",
    "files=list()\n",
    "newsFiles=listdir(\"/home/andrea/Desktop/NLFF/intrinioDataset\")\n",
    "indexesFiles=listdir(\"/home/andrea/Desktop/NLFF/DataSetIndexes\")\n",
    "#print(newsFiles)\n",
    "#print(indexesFiles)\n",
    "tickers=list()\n",
    "for file in indexesFiles:\n",
    "    file=re.sub('\\.csv$', '', file)\n",
    "    file=re.sub('indexes', '', file)\n",
    "    tickers.append(file)\n",
    "tickers.sort()\n",
    "print(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#tickers=[\"AAPL\"]\n",
    "\n",
    "for ticker in tickers:\n",
    "    data = list()\n",
    "    timeSpan = list()\n",
    "    print(\"Working on \"+ticker+\"...\")\n",
    "    \n",
    "    #VARIABILE PER SETTARE DELAY DELLE NEWS IN MIN\n",
    "    delay=20\n",
    "    reader=pd.read_csv('/home/andrea/Desktop/NLFF/intrinioDataset/preprocessing/preprocessed/'+ticker+'.csv') #reader = csv.DictReader(csvfile)\n",
    "    for row in reader.T.iteritems():\n",
    "        time  = datetime.strptime(row[1]['PUBLICATION_DATE'], '%Y-%m-%d %H:%M:%S +%f')\n",
    "        time=time+timedelta(minutes=delay)\n",
    "        data.append({'time':time, 'summary':row[1]['SUMMARY']}) \n",
    "\n",
    "\n",
    "    reader = pd.read_csv('/home/andrea/Desktop/NLFF/DataSetIndexes/indexes'+ticker+'.csv')\n",
    "    reader.rename(columns={'Unnamed: 0':'date'}, inplace=True)\n",
    "    for row in reader.T.iteritems():\n",
    "        time  = datetime.strptime(row[1]['date'], '%Y-%m-%d %H:%M:%S')\n",
    "        timeSpan.append(time) \n",
    "\n",
    "\n",
    "\n",
    "    i = len(data)-1;\n",
    "    j=0;\n",
    "    \n",
    "    #Nuova colonna al dataframe per il sentiment\n",
    "    reader[\"sentiment\"] = np.nan\n",
    "    \n",
    "    initDate = max(timeSpan[0], data[len(data)-1]['time'])\n",
    "    finalDate = min(timeSpan[len(timeSpan)-1], data[0]['time'])\n",
    "    \n",
    "    # ALLINEAMENTO INIZIO\n",
    "    while(timeSpan[j] < initDate):\n",
    "        j+=1\n",
    "    while(data[i]['time'] <= initDate):\n",
    "        i-=1\n",
    "        \n",
    "\n",
    "    weighted_sum = 0;\n",
    "    normal_sum = 0\n",
    "    while( data[i]['time'] < finalDate and timeSpan[j] < finalDate ):\n",
    "        \n",
    "        total_subj = INITIAL_WEIGHT\n",
    "        num_sentiment = 1\n",
    "        \n",
    "        initTime = timeSpan[j]\n",
    "        \n",
    "        while(i>0 and timeSpan[j] > data[i]['time']):\n",
    "            if not (timeSpan[j] > data[i]['time'] and timeSpan[j-1] <= data[i]['time']):\n",
    "                print(\"timeSpan[\"+str(j)+\"]: \"+str(timeSpan[j])+\" data[\"+str(i)+\"] : \" +str(data[i]['time']) + \" timeSpan[\"+str(j-1)+\"]: \"+str(timeSpan[j-1]))\n",
    "                assert False\n",
    "            try:\n",
    "                subjectivity = 1\n",
    "                \n",
    "                polarity=FilSentimentExtract.estractSentimentFil(data[i]['summary'].decode('utf-8'))\n",
    "                \n",
    "                if(polarity==100 ):\n",
    "                    \n",
    "                    content=senticAPIextractor.extractPolarity(data[i]['summary'].decode('utf-8'))\n",
    "                    if(content['polarity']=='positive'):\n",
    "                        polarity=1\n",
    "                    else:\n",
    "                        polarity=-1\n",
    "\n",
    "                normal_sum += polarity\n",
    "\n",
    "                weighted_sum += polarity*subjectivity\n",
    "                \n",
    "                total_subj+=subjectivity\n",
    "                num_sentiment +=1\n",
    "            except Exception as e: \n",
    "                    print(e)\n",
    "                    #print(data[i]['summary'])\n",
    "\n",
    "            i-=1\n",
    "            \n",
    "        weighted_sum /=total_subj\n",
    "        normal_sum /=num_sentiment\n",
    "        reader[\"sentiment\"].at[j] = normal_sum    \n",
    "        j+=1\n",
    "\n",
    "        print('normal sum: '+str(normal_sum))\n",
    "\n",
    "    #Write results\n",
    "    reader = reader[pd.isnull(reader['sentiment']) == False ]\n",
    "    \n",
    "    reader.to_csv('/home/andrea/Desktop/NLFF/DataSetSentimentWithFil/sentiment20minutes'+ticker+'.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
