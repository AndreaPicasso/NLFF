{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import senticnet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentic_concepts_and_scores_csv(field, ticker):\n",
    "    source_dir = '/home/andrea/Desktop/NLFF/intrinioDatasetUpdated/preprocessing/preprocessed/'\n",
    "    dest_dir = 'conceptsDataset/summary/'+str(ticker)+'.csv'\n",
    "    tickFiles = [f for f in listdir(source_dir) if isfile(join(source_dir, f))]\n",
    "    source_df = pd.read_csv(source_dir+ticker+'.csv')\n",
    "    count =1\n",
    "    while str(ticker)+str(count)+'.csv' in tickFiles:\n",
    "        print(ticker+str(count))\n",
    "        newsTemp = pd.read_csv(source_dir + ticker +str(count)+'.csv')\n",
    "        source_df = pd.concat([source_df, newsTemp])\n",
    "        count+=1\n",
    "    source_df = source_df.rename(index=str, columns={\"PUBLICATION_DATE\": \"DATE\"})\n",
    "    source_df.drop_duplicates(subset=['DATE'], inplace=True)\n",
    "    source_df = source_df.sort_values(by=['DATE'])\n",
    "    source_df = source_df.reset_index(drop=True)\n",
    "    \n",
    "    source_df['concepts'] = ''\n",
    "    source_df['polarity'] = ''\n",
    "    source_df['attention'] = ''\n",
    "    source_df['pleasantness'] = ''\n",
    "    source_df['aptitude'] = ''\n",
    "    source_df['sensitivity'] = ''\n",
    "\n",
    "    sn = senticnet.Senticnet()\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    counter = 0\n",
    "    null = 0\n",
    "    stemmed_null = 0\n",
    "    for index, row in source_df.iterrows():\n",
    "        concepts = []\n",
    "        concept_scores = {'polarity' : 0, 'attention': 0, 'pleasantness': 0, 'aptitude': 0, 'sensitivity': 0}\n",
    "        stemmed_concepts = []\n",
    "        stemmed_concept_scores = {'polarity': 0, 'attention': 0, 'pleasantness': 0, 'aptitude': 0, 'sensitivity': 0}\n",
    "\n",
    "        if isinstance(row[field], float):\n",
    "            content = ''\n",
    "            stemmed_title = ''\n",
    "        else:\n",
    "            content = '_' + row[field].replace(' ', '_').lower() + '_'\n",
    "            stemmed_title = '_' + '_'.join([stemmer.stem(t) for t in row[field].lower().split()]) + '_'\n",
    "        # print(stemmed_title)\n",
    "        for concept_key in sn.data.keys():\n",
    "            if '_' + concept_key +'_' in content:\n",
    "                concepts.append(concept_key)\n",
    "                concept_data = sn.concept(concept_key)\n",
    "                concept_scores['polarity'] += concept_data['polarity']\n",
    "                concept_scores['attention'] += concept_data['sentics']['attention']\n",
    "                concept_scores['pleasantness'] += concept_data['sentics']['pleasantness']\n",
    "                concept_scores['aptitude'] += concept_data['sentics']['aptitude']\n",
    "                concept_scores['sensitivity'] += concept_data['sentics']['sensitivity']\n",
    "            if '_' + concept_key +'_' in stemmed_title:\n",
    "                stemmed_concepts.append(concept_key)\n",
    "                concept_data = sn.concept(concept_key)\n",
    "                stemmed_concept_scores['polarity'] += concept_data['polarity']\n",
    "                stemmed_concept_scores['attention'] += concept_data['sentics']['attention']\n",
    "                stemmed_concept_scores['pleasantness'] += concept_data['sentics']['pleasantness']\n",
    "                stemmed_concept_scores['aptitude'] += concept_data['sentics']['aptitude']\n",
    "                stemmed_concept_scores['sensitivity'] += concept_data['sentics']['sensitivity']\n",
    "\n",
    "        # print(concept_scores)\n",
    "        if len(concepts) > 0:\n",
    "            for k, v in concept_scores.items():\n",
    "                concept_scores[k] /= len(concepts)\n",
    "        else:\n",
    "            null +=1\n",
    "        if len(stemmed_concepts) > 0:\n",
    "            for k, v in stemmed_concept_scores.items():\n",
    "                stemmed_concept_scores[k] /= len(stemmed_concepts)\n",
    "        else:\n",
    "            stemmed_null +=1\n",
    "\n",
    "        # print(concept_scores)\n",
    "        source_df.set_value(index, 'polarity', concept_scores['polarity'])\n",
    "        source_df.set_value(index, 'attention', concept_scores['attention'])\n",
    "        source_df.set_value(index, 'pleasantness', concept_scores['pleasantness'])\n",
    "        source_df.set_value(index, 'aptitude', concept_scores['aptitude'])\n",
    "        source_df.set_value(index, 'sensitivity', concept_scores['sensitivity'])\n",
    "        source_df.set_value(index, 'concepts', ' '.join(concepts))\n",
    "        source_df.set_value(index, 'stemmed_polarity', stemmed_concept_scores['polarity'])\n",
    "        source_df.set_value(index, 'stemmed_attention', stemmed_concept_scores['attention'])\n",
    "        source_df.set_value(index, 'stemmed_pleasantness', stemmed_concept_scores['pleasantness'])\n",
    "        source_df.set_value(index, 'stemmed_aptitude', stemmed_concept_scores['aptitude'])\n",
    "        source_df.set_value(index, 'stemmed_sensitivity', stemmed_concept_scores['sensitivity'])\n",
    "        source_df.set_value(index, 'stemmed_concepts', ' '.join(stemmed_concepts))\n",
    "\n",
    "        # joblib.dump(concept_scores, os.path.join(config.SENTIC_SCORES_DATA_DIR + file.replace('.txt', '.pkl')))\n",
    "        counter += 1\n",
    "        if(counter % 500 == 0):\n",
    "            print(counter)\n",
    "        # break\n",
    "    print('Null: ',null,' Stemmed Null: ',stemmed_null )\n",
    "    source_df.to_csv(dest_dir, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tickers = ['AAPL','AMZN','GOOGL','MSFT','FB','INTC','CSCO','CMCSA','NVDA','NFLX'] \n",
    "tickers=['PEP','BKNG','ADBE','AMGN','TXN','AVGO','PYPL','GILD','COST','QCOM'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrea/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:74: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/andrea/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:75: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/andrea/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:76: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/andrea/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:77: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/andrea/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:78: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/andrea/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:79: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/andrea/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:80: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/andrea/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:81: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/andrea/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:82: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/andrea/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:83: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/andrea/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:84: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/andrea/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:85: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "Null:  21  Stemmed Null:  20\n",
      "BKNG\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "Null:  12  Stemmed Null:  14\n",
      "ADBE\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "Null:  9  Stemmed Null:  8\n",
      "AMGN\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "Null:  66  Stemmed Null:  70\n",
      "TXN\n",
      "500\n",
      "1000\n",
      "1500\n",
      "Null:  45  Stemmed Null:  5\n",
      "AVGO\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "Null:  35  Stemmed Null:  44\n",
      "PYPL\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "Null:  53  Stemmed Null:  27\n",
      "GILD\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "Null:  72  Stemmed Null:  81\n",
      "COST\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "Null:  33  Stemmed Null:  26\n",
      "QCOM\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "Null:  46  Stemmed Null:  46\n"
     ]
    }
   ],
   "source": [
    "for ticker in tickers:\n",
    "    print(ticker)\n",
    "    extract_sentic_concepts_and_scores_csv('SUMMARY', ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
