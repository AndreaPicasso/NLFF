{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_json('/home/simone/Desktop/wordCountEmbedding.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "1000\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "1100\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "1200\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "1300\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "1400\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "1500\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "1600\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "1700\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "1800\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "1900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "200\n",
      "2000\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "2100\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "21400\n",
      "21500\n",
      "21600\n",
      "21700\n",
      "21800\n",
      "21900\n",
      "2200\n",
      "22000\n",
      "22100\n",
      "22200\n",
      "22300\n",
      "22400\n",
      "22500\n",
      "22600\n",
      "22700\n",
      "22800\n",
      "22900\n",
      "2300\n",
      "23000\n",
      "23100\n",
      "23200\n",
      "23300\n",
      "23400\n",
      "23500\n",
      "23600\n",
      "23700\n",
      "23800\n",
      "23900\n",
      "2400\n",
      "24000\n",
      "24100\n",
      "24200\n",
      "24300\n",
      "24400\n",
      "24500\n",
      "24600\n",
      "24700\n",
      "24800\n",
      "24900\n",
      "2500\n",
      "25000\n",
      "25100\n",
      "25200\n",
      "25300\n",
      "25400\n",
      "25500\n",
      "25600\n",
      "25700\n",
      "25800\n",
      "25900\n",
      "2600\n",
      "26000\n",
      "26100\n",
      "26200\n",
      "26300\n",
      "26400\n",
      "26500\n",
      "26600\n",
      "26700\n",
      "26800\n",
      "26900\n",
      "2700\n",
      "27000\n",
      "27100\n",
      "27200\n",
      "27300\n",
      "27400\n",
      "27500\n",
      "27600\n",
      "27700\n",
      "27800\n",
      "27900\n",
      "2800\n",
      "28000\n",
      "28100\n",
      "28200\n",
      "28300\n",
      "28400\n",
      "28500\n",
      "28600\n",
      "28700\n",
      "2900\n",
      "300\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "400\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "500\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "600\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "700\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "800\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n"
     ]
    }
   ],
   "source": [
    "toRemove = []\n",
    "for i, row in dataset.iterrows():\n",
    "    if(i % 100 == 0):\n",
    "        print(i)\n",
    "    dataset['EMBEDDING'].at[i] = dataset['EMBEDDING'].at[i][0]\n",
    "    if(dataset['EMBEDDING'][i][0]==None):\n",
    "        toRemove.append(i)\n",
    "    #Troppi sample con tutto a 0, ne rimuovo 2/3\n",
    "    if(dataset['NEGATIVE'][i]+dataset['POSITIVE'][i]+dataset['CONSTRAINING'][i]\n",
    "           +dataset['LITIGIOUS'][i]+dataset['UNCERTAINTY'][i] == 0):\n",
    "        if(random.random() < 0.7):\n",
    "            toRemove.append(i)\n",
    "\n",
    "\n",
    "dataset = dataset.drop(toRemove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2886\n",
      "21709\n"
     ]
    }
   ],
   "source": [
    "tot = 0\n",
    "for i, row in dataset.iterrows():\n",
    "    if(dataset['NEGATIVE'][i]+dataset['POSITIVE'][i]+dataset['CONSTRAINING'][i]\n",
    "           +dataset['LITIGIOUS'][i]+dataset['UNCERTAINTY'][i] == 0):\n",
    "        tot +=1\n",
    "        \n",
    "print(tot)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "y_label = ['NEGATIVE','POSITIVE', 'CONSTRAINING','LITIGIOUS','UNCERTAINTY']\n",
    "\n",
    "idx_split = math.floor(len(dataset)*(0.7))\n",
    "\n",
    "train_x = dataset['EMBEDDING'][:idx_split].tolist()\n",
    "train_y =dataset[y_label][:idx_split]\n",
    "test_x = dataset['EMBEDDING'][idx_split:].tolist()\n",
    "test_y = dataset[y_label][idx_split:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12835866\n",
      "Epoch: 0001 training cost= 0.749609351 test cost= 0.257318109\n",
      "0.12835866\n",
      "Epoch: 0002 training cost= 0.512114704 test cost= 0.257318109\n",
      "0.12835866\n",
      "Epoch: 0003 training cost= 0.512114704 test cost= 0.257318109\n",
      "0.12835866\n",
      "Epoch: 0004 training cost= 0.512114704 test cost= 0.257318109\n",
      "0.12835866\n",
      "Epoch: 0005 training cost= 0.512114704 test cost= 0.257318109\n",
      "0.12835866\n",
      "Epoch: 0006 training cost= 0.512114704 test cost= 0.257318109\n",
      "0.12835866\n",
      "Epoch: 0007 training cost= 0.512094706 test cost= 0.257318109\n",
      "0.12835866\n",
      "Epoch: 0008 training cost= 0.512094706 test cost= 0.257318109\n",
      "0.12835866\n",
      "Epoch: 0009 training cost= 0.512094706 test cost= 0.257318109\n",
      "0.12835866\n",
      "Epoch: 0010 training cost= 0.512094706 test cost= 0.257318109\n",
      "0.1285122\n",
      "Epoch: 0011 training cost= 0.512094706 test cost= 0.257287413\n",
      "0.1285122\n",
      "Epoch: 0012 training cost= 0.512074709 test cost= 0.257287413\n",
      "0.12912637\n",
      "Epoch: 0013 training cost= 0.512068063 test cost= 0.257225990\n",
      "0.1292799\n",
      "Epoch: 0014 training cost= 0.511991084 test cost= 0.257151395\n",
      "0.12989406\n",
      "Epoch: 0015 training cost= 0.511911064 test cost= 0.256936431\n",
      "0.13066176\n",
      "Epoch: 0016 training cost= 0.511774093 test cost= 0.256741971\n",
      "0.13096884\n",
      "Epoch: 0017 training cost= 0.511727422 test cost= 0.256649852\n",
      "0.1320436\n",
      "Epoch: 0018 training cost= 0.511832416 test cost= 0.256334603\n",
      "0.13373253\n",
      "Epoch: 0019 training cost= 0.511451125 test cost= 0.256027520\n",
      "0.13450024\n",
      "Epoch: 0020 training cost= 0.511065841 test cost= 0.255814582\n",
      "Optimization Finished!\n",
      "       NEGATIVE  POSITIVE  CONSTRAINING  LITIGIOUS  UNCERTAINTY\n",
      "27827  0.000000  0.000000           0.0        0.0          0.0\n",
      "2783   1.000000  0.000000           0.0        0.0          0.0\n",
      "27830  0.000000  0.000000           0.0        0.0          1.0\n",
      "27831  0.500000  0.000000           0.0        0.0          0.5\n",
      "27832  0.000000  1.000000           0.0        0.0          0.0\n",
      "27833  0.000000  0.000000           0.0        1.0          0.0\n",
      "27834  0.500000  0.000000           0.0        0.5          0.0\n",
      "27835  0.000000  1.000000           0.0        0.0          0.0\n",
      "27836  0.500000  0.000000           0.0        0.5          0.0\n",
      "27837  0.666667  0.333333           0.0        0.0          0.0\n",
      "[[0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f48dafd9eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = 1\n",
    "training_epochs = 20\n",
    "batch_size = 10000\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 512 # 1st layer number of neurons\n",
    "n_hidden_2 = 512 # 2nd layer number of neurons\n",
    "n_input = 2400\n",
    "n_classes = 5\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1],stddev=5)),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2],stddev=5)),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes],stddev=5))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1],stddev=5)),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2],stddev=5)),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes],stddev=5))\n",
    "}\n",
    "\n",
    "def random_mini_batches(X_train, Y_train, minibatch_size):\n",
    "    minibatches = list()\n",
    "\n",
    "    m = int(len(X_train))\n",
    "    if(minibatch_size > m):\n",
    "        minibatches.append((X_train, Y_train))\n",
    "        return minibatches\n",
    "\n",
    "    minibatches.append((X_train[0:minibatch_size], Y_train[0:minibatch_size]))\n",
    "    iterSize = minibatch_size\n",
    "    while(iterSize < m):\n",
    "        if(iterSize+minibatch_size < m):\n",
    "            minibatches.append((X_train[iterSize:iterSize+minibatch_size], Y_train[iterSize:iterSize+minibatch_size]))\n",
    "            iterSize += minibatch_size\n",
    "        else:\n",
    "            minibatches.append((X_train[iterSize:m],Y_train[iterSize:m]))\n",
    "            iterSize = m\n",
    "    return minibatches\n",
    "\n",
    "\n",
    "def multilayer_perceptron(x):\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.nn.relu(tf.add(tf.matmul(x, weights['h1']), biases['b1']))\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, weights['h2']), biases['b2']))\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.sigmoid(tf.add(tf.matmul(layer_2, weights['out']), biases['out']))\n",
    "    return out_layer\n",
    "\n",
    "# Construct model\n",
    "logits = multilayer_perceptron(X)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.squared_difference(logits, Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    num_minibatches = int(len(train_x) / batch_size)\n",
    "    if(num_minibatches == 0):\n",
    "        num_minibatches = 1\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        minibatches = random_mini_batches(train_x,train_y, batch_size)\n",
    "        # Loop over all batches\n",
    "        for minibatch in minibatches:\n",
    "            (minibatch_X, minibatch_Y) = minibatch\n",
    "            minibatch_X = np.asarray(minibatch_X)            \n",
    "            minibatch_Y = np.asarray(minibatch_Y).reshape((len(minibatch_Y), n_classes))\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([train_op, loss_op], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "            # Compute average loss\n",
    "            #print(c)\n",
    "            avg_cost += c / num_minibatches\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            accuracy_train.append(avg_cost)\n",
    "            test_loss = sess.run(loss_op, feed_dict={X: test_x, Y: test_y})\n",
    "            accuracy_test.append(test_loss)\n",
    "            print(sess.run(accuracy, feed_dict={X: test_x, Y: test_y}))\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"training cost= {:.9f}\".format(avg_cost), \"test cost= {:.9f}\".format(test_loss))\n",
    "    print(\"Optimization Finished!\")\n",
    "    pred = sess.run(logits, feed_dict={X: test_x, Y: test_y})\n",
    "    print(test_y[:10])\n",
    "    print(pred[:10])\n",
    "    # Test model\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(np.arange(0, training_epochs), accuracy_train,'b')\n",
    "plt.plot(np.arange(0, training_epochs), accuracy_test,'r')\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('epochs')\n",
    "plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
