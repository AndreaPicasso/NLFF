{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrea/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "============================================================\n",
      "Working on window: 1\n",
      "ModelSelection\n",
      "Best Accuracy on validation: 0.5342272367755988\n",
      "BestLearning: 1e-05\n",
      "BestDrop: 0.25\n",
      "BestNeuron: 2\n",
      "[0.6973095504952589, 0.4927113737813238]\n",
      "[0.700129195495888, 0.47222222190028357]\n",
      "LOOK HOW IT WORKS WITH TEST SET....\n",
      "Accuracy on test set\n",
      "0.472303213209522\n",
      "0.5247813411078717\n",
      "on new\n",
      "0.5000000003679299\n",
      "============================================================\n",
      "============================================================\n",
      "Working on window: 4\n",
      "ModelSelection\n",
      "Best Accuracy on validation: 0.5510948965239055\n",
      "BestLearning: 0.1\n",
      "BestDrop: 0\n",
      "BestNeuron: 4\n",
      "[0.6973903789157756, 0.5175438647033178]\n",
      "[0.698528813464301, 0.5119047617717158]\n",
      "LOOK HOW IT WORKS WITH TEST SET....\n",
      "Accuracy on test set\n",
      "0.5058479563534608\n",
      "0.5058479532163743\n",
      "on new\n",
      "0.5000000003547895\n",
      "============================================================\n",
      "============================================================\n",
      "Working on window: 12\n",
      "ModelSelection\n",
      "Best Accuracy on validation: 0.5831741138551337\n",
      "BestLearning: 0.1\n",
      "BestDrop: 0\n",
      "BestNeuron: 4\n",
      "[0.7347991749687978, 0.51319648443429]\n",
      "[0.7409182090357126, 0.5000000007181282]\n",
      "LOOK HOW IT WORKS WITH TEST SET....\n",
      "Accuracy on test set\n",
      "0.51319648443429\n",
      "0.5131964809384164\n",
      "on new\n",
      "0.5000000007181282\n",
      "============================================================\n",
      "============================================================\n",
      "Working on window: 20\n",
      "ModelSelection\n",
      "Best Accuracy on validation: 0.6202342099256505\n",
      "BestLearning: 1e-05\n",
      "BestDrop: 0.5\n",
      "BestNeuron: 3\n",
      "[0.6915630483697649, 0.5221238941569596]\n",
      "[0.6939346970599375, 0.5000000000919824]\n",
      "LOOK HOW IT WORKS WITH TEST SET....\n",
      "Accuracy on test set\n",
      "0.5221238941569596\n",
      "0.5221238938053098\n",
      "on new\n",
      "0.5000000000919824\n",
      "============================================================\n",
      "============================================================\n",
      "Working on window: 24\n",
      "ModelSelection\n",
      "Best Accuracy on validation: 0.6106154723819304\n",
      "BestLearning: 0.0001\n",
      "BestDrop: 0\n",
      "BestNeuron: 2\n",
      "[0.6815131430089827, 0.5473372781505952]\n",
      "[0.6950090511951571, 0.5000000003895728]\n",
      "LOOK HOW IT WORKS WITH TEST SET....\n",
      "Accuracy on test set\n",
      "0.452662722510699\n",
      "0.5473372781065089\n",
      "on new\n",
      "0.4999999996104272\n",
      "============================================================\n",
      "============================================================\n",
      "Working on window: 26\n",
      "ModelSelection\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(13)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import keras\n",
    "import predictonlyup\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras import optimizers\n",
    "from __future__ import division\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def findMaxAcc(valacc,valloss):\n",
    "\tprevloss=valloss[0]\n",
    "\tfor i in range(1,len(valloss)):\n",
    "\t\tif(valloss[i]>prevloss):\n",
    "\t\t\treturn valacc[i-1]\n",
    "\t#print('Problems with find MaxAccuracy')\n",
    "\treturn valacc[len(valacc)-1]\n",
    "\n",
    "\n",
    "ticker='ADBE'\n",
    "price= pd.read_csv('/home/andrea/Desktop/NLFF/DataSetIndexesLabeled/indexes'+ticker+'.csv')\n",
    "if(ticker=='AAPL'):\n",
    "    ticker='AAPL_tot'\n",
    "sentimentVector =  pd.read_csv('SentimentNews/'+ticker+'.csv')\n",
    "#alignment of data\n",
    "maxdata=max(sentimentVector['initTime'])\n",
    "mindata=min(sentimentVector['initTime'])\n",
    "price=price[price['Unnamed: 0']>=mindata]\n",
    "price=price[price['Unnamed: 0']<=maxdata]\n",
    "#remove the time from data\n",
    "sentimentVector=sentimentVector.drop(['Unnamed: 0', 'initTime' ], axis=1)\n",
    "#2\n",
    "#label because of the market and append values without datatime\n",
    "#Important to set lenth of trend in this to see if news affect from today to today+tendwindowtime\n",
    "#this is theorical (looks at difference betwwen price before news and price after news)because for make it real i have to change price.iloc[i-1]['open'] to price.iloc[i]['open']\n",
    "#because the trader can buy only on price.iloc[i]['open'] that is today\n",
    "trendwindowtime=[1,4,12,20,24,26,30,35,40,48,60]\n",
    "for t in trendwindowtime:\n",
    "    #1\n",
    "#label because of the maket and append values without data\n",
    "#simo theroy past trend\n",
    "    x=[]\n",
    "    y=[]\n",
    "    print('============================================================')\n",
    "    print('============================================================')\n",
    "    print('Working on window:',t)\n",
    "    for i in range(1,len(price)-t):\n",
    "\n",
    "        y.append(np.sign(price.iloc[i+t]['close']-price.iloc[i-1]['open']))\n",
    "        x.append(sentimentVector.iloc[i].values)\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    y=(y+1)/2\n",
    "    \n",
    "    #Split betwwen train-validation and test\n",
    "    train=0.8\n",
    "    nt=math.ceil(len(x)*train)\n",
    "    x_tv=[]\n",
    "    y_tv=[]\n",
    "    x_test=[]\n",
    "    y_test=[]\n",
    "    x_tv=x[:nt]\n",
    "    y_tv=y[:nt]\n",
    "    x_test=x[nt:]\n",
    "    y_test=y[nt:]\n",
    "    \n",
    "    #Fairly sampling the test 50% 50%\n",
    "    posindex=np.where( y_test == 1 )\n",
    "    negindex=np.where( y_test == 0 )\n",
    "    \n",
    "    yindex=[]\n",
    "    nindex=min(len(posindex[0]),len(negindex[0]))\n",
    "    \n",
    "    #for i in range(1,nindex):\n",
    "    y_testnew=np.concatenate((y_test[posindex[0][0:nindex]],y_test[negindex[0][0:nindex]]))\n",
    "    x_testnew=np.concatenate((x_test[posindex[0][0:nindex]],x_test[negindex[0][0:nindex]]))\n",
    "    \n",
    "    nfold=10\n",
    "    kf = KFold(n_splits=nfold, random_state=13, shuffle=True)\n",
    "\n",
    "\n",
    "    #model selection\n",
    "    learningrate=[0.1,0.01,0.001,0.0001,0.00001]\n",
    "    drop=[0,0.25,0.5]\n",
    "    neurons=[2,3,4,5]\n",
    "    bestacc=0\n",
    "    bestl=0\n",
    "    bestdrop=0\n",
    "    bestneuron=0\n",
    "    bestmodel=None\n",
    "    cvaccuracy=[]\n",
    "    print('ModelSelection')\n",
    "    for l in learningrate:\n",
    "        for d in drop:\n",
    "            for n in neurons:\n",
    "                #print(l)\n",
    "                #crossvalidation\n",
    "                opt=keras.optimizers.SGD(lr=l, momentum=0.0, decay=0.0, nesterov=False)\n",
    "                model = Sequential()\n",
    "                model.add(Dense(n, input_shape=(5,), activation='sigmoid'))\n",
    "                model.add(Dropout(d))\n",
    "                model.add(Dense(1, activation='sigmoid'))\n",
    "                model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "                cvaccuracy=[]\n",
    "                for train_index, test_index in kf.split(x_tv):\n",
    "                    x_train, x_val = x_tv[train_index], x_tv[test_index]\n",
    "                    y_train, y_val = y_tv[train_index], y_tv[test_index]\n",
    "                    history=model.fit(x_train, y_train, epochs=20, verbose=0,batch_size=10,validation_data=(x_val, y_val))\n",
    "\n",
    "                    maxAcc=findMaxAcc(history.history['val_acc'],history.history['val_loss'])\n",
    "                    cvaccuracy.append(maxAcc)\n",
    "                mcvaccuracy=sum(cvaccuracy)/len(cvaccuracy)\n",
    "\n",
    "                if(mcvaccuracy>bestacc):\n",
    "                    bestacc=mcvaccuracy\n",
    "                    bestl=l\n",
    "                    bestdrop=d\n",
    "                    bestneuron=n\n",
    "                    bestmodel=model\n",
    "    print('Best Accuracy on validation:',bestacc)\n",
    "    print('BestLearning:',bestl)\n",
    "    print('BestDrop:',bestdrop)\n",
    "    print('BestNeuron:',bestneuron)\n",
    "    print(bestmodel.evaluate(x=x_test, y=y_test, batch_size=10, verbose=0))\n",
    "    print(bestmodel.evaluate(x=x_testnew, y=y_testnew, batch_size=10, verbose=0))\n",
    "    tot=[]\n",
    "    print('LOOK HOW IT WORKS WITH TEST SET....')\n",
    "    opt=keras.optimizers.SGD(lr=bestl, momentum=0.0, decay=0.0, nesterov=False)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(bestneuron, input_shape=(5,), activation='sigmoid'))\n",
    "    model.add(Dropout(bestdrop))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    model.fit(x_tv, y_tv, epochs=20, verbose=0,batch_size=10)\n",
    "    evaluation=model.evaluate(x=x_test, y=y_test, batch_size=10, verbose=0)\n",
    "    evaluation1=model.evaluate(x=x_testnew, y=y_testnew, batch_size=10, verbose=0)\n",
    "    acc=evaluation[1]\n",
    "    acc1=evaluation1[1]\n",
    "    print('Accuracy on test set')\n",
    "    print(acc)\n",
    "    print(predictonlyup.alwaysUp(y_test))\n",
    "    print('on new')\n",
    "    print(acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
