{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrea/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "============================================================\n",
      "Working on window: 1\n",
      "554\n",
      "554\n",
      "ModelSelection\n",
      "\n",
      "0.5188545151863875\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.5347036423731633\n",
      "Best Accuracy on validation: 0.5347036423731633\n",
      "BestLearning: 0.0001\n",
      "BestDrop: 0\n",
      "BestNeuron: 64\n",
      "LOOK HOW IT WORKS WITH TEST SET....\n",
      "Accuracy on test set\n",
      "0.5000000000274929\n",
      "============================================================\n",
      "============================================================\n",
      "Working on window: 4\n",
      "554\n",
      "554\n",
      "ModelSelection\n",
      "\n",
      "0.5140879397648364\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.5171080402893262\n",
      "\n",
      "\n",
      "\n",
      "0.5191080404177832\n",
      "Best Accuracy on validation: 0.5191080404177832\n",
      "BestLearning: 0.0001\n",
      "BestDrop: 0\n",
      "BestNeuron: 64\n",
      "LOOK HOW IT WORKS WITH TEST SET....\n",
      "Accuracy on test set\n",
      "0.5000000004481552\n",
      "============================================================\n",
      "============================================================\n",
      "Working on window: 20\n",
      "551\n",
      "551\n",
      "ModelSelection\n",
      "\n",
      "0.5011655265263553\n",
      "\n",
      "0.5113451673962879\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.53629526709912\n",
      "\n",
      "\n",
      "0.5634908759446524\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.6298189334175144\n",
      "Best Accuracy on validation: 0.6298189334175144\n",
      "BestLearning: 0.0001\n",
      "BestDrop: 0\n",
      "BestNeuron: 64\n",
      "LOOK HOW IT WORKS WITH TEST SET....\n",
      "Accuracy on test set\n",
      "0.49999999953973245\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(13)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras import optimizers\n",
    "from __future__ import division\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def findMaxAcc(valacc,valloss):\n",
    "\tprevloss=valloss[0]\n",
    "\tfor i in range(1,len(valloss)):\n",
    "\t\tif(valloss[i]>prevloss):\n",
    "\t\t\treturn valacc[i-1]\n",
    "\t#print('Problems with find MaxAccuracy')\n",
    "\treturn valacc[len(valacc)-1]\n",
    "\n",
    "ticker='AAPL'\n",
    "y=[]\n",
    "price=pd.read_csv('/home/andrea/Desktop/NLFF/indexesLabeledNew/indexes'+ticker+'.csv')\n",
    "#print(price)\n",
    "trendwindowtime=[1,4,20]\n",
    "price=price.iloc[2500:]\n",
    "#xtemp=price[['open','close','volume','macd','macds', 'boll_ub', 'boll_lb','rsi_6','rsi_12','vr_6_sma','wr_10','wr_6']]\n",
    "xtemp=price[['open','close']]\n",
    "xtemp=np.nan_to_num(np.asarray(xtemp, dtype=float))\n",
    "for t in trendwindowtime:\n",
    "    #1\n",
    "#label because of the maket and append values without data\n",
    "#simo theroy past trend\n",
    "    x=[]\n",
    "    y=[]\n",
    "    print('============================================================')\n",
    "    print('============================================================')\n",
    "    print('Working on window:',t)\n",
    "    \n",
    "    for i in range(0,len(price)-t):\n",
    "        y.append(np.sign(price.iloc[i+t]['close']-price.iloc[i]['open']))\n",
    "        x.append(xtemp[i])\n",
    "    y=np.array(y)\n",
    "    x=np.array(x)\n",
    "    y=(y+1)/2\n",
    "    \n",
    "    #Split betwwen train-validation and test\n",
    "    \n",
    "    train=0.8\n",
    "    nt=math.ceil(len(x)*train)\n",
    "    x_tv=[]\n",
    "    y_tv=[]\n",
    "    x_test=[]\n",
    "    y_test=[]\n",
    "    x_tv=x[:nt]\n",
    "    y_tv=y[:nt]\n",
    "    x_test=x[nt:]\n",
    "    y_test=y[nt:]\n",
    "    print(len(x_test))\n",
    "    print(len(y_test))\n",
    "    \n",
    "    #Fairly sampling the tv\n",
    "    posindex=np.where( y_tv == 1 )\n",
    "    negindex=np.where( y_tv == 0 )\n",
    "    \n",
    "    yindex=[]\n",
    "    nindex=min(len(posindex[0]),len(negindex[0]))\n",
    "    \n",
    "    #for i in range(1,nindex):\n",
    "    y_tvnew=np.concatenate((y_tv[posindex[0][0:nindex]],y_tv[negindex[0][0:nindex]]))\n",
    "    x_tvnew=np.concatenate((x_tv[posindex[0][0:nindex]],x_tv[negindex[0][0:nindex]]))\n",
    "    \n",
    "    #Fairly sampling the test 50% 50%\n",
    "    posindex=np.where( y_test == 1 )\n",
    "    negindex=np.where( y_test == 0 )\n",
    "    \n",
    "    yindex=[]\n",
    "    nindex=min(len(posindex[0]),len(negindex[0]))\n",
    "    \n",
    "    #for i in range(1,nindex):\n",
    "    \n",
    "\n",
    "    y_testnew=np.concatenate((y_test[posindex[0][0:nindex]],y_test[negindex[0][0:nindex]]))\n",
    "    x_testnew=np.concatenate((x_test[posindex[0][0:nindex]],x_test[negindex[0][0:nindex]]))\n",
    "    \n",
    "    nfold=10\n",
    "    kf = KFold(n_splits=nfold, random_state=13, shuffle=True)\n",
    "\n",
    "\n",
    "    #model selection\n",
    "    learningrate=[0.1,0.01,0.001,0.0001]\n",
    "    drop=[0]\n",
    "    neurons=[5,16,64]\n",
    "    bestacc=0\n",
    "    bestl=0\n",
    "    bestdrop=0\n",
    "    bestneuron=0\n",
    "    \n",
    "    cvaccuracy=[]\n",
    "    print('ModelSelection')\n",
    "    for l in learningrate:\n",
    "        for d in drop:\n",
    "            for n in neurons:\n",
    "                #print(l)\n",
    "                print()\n",
    "                opt=keras.optimizers.SGD(lr=l, momentum=0.0, decay=0.0, nesterov=False)\n",
    "                model = Sequential()\n",
    "                model.add(Dense(n, input_shape=(2,), activation='sigmoid'))\n",
    "                model.add(Dropout(d))\n",
    "                model.add(Dense(n, activation='sigmoid'))\n",
    "                model.add(Dropout(d))\n",
    "                model.add(Dense(1, activation='sigmoid'))\n",
    "                model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "                cvaccuracy=[]\n",
    "                #crossvalidation\n",
    "                for train_index, test_index in kf.split(x_tvnew):\n",
    "                    x_train, x_val = x_tvnew[train_index], x_tvnew[test_index]\n",
    "                    y_train, y_val = y_tvnew[train_index], y_tvnew[test_index]\n",
    "                    history=model.fit(x_train, y_train, epochs=20, verbose=0,batch_size=10,validation_data=(x_val, y_val))\n",
    "\n",
    "                    maxAcc=findMaxAcc(history.history['val_acc'],history.history['val_loss'])\n",
    "                    cvaccuracy.append(maxAcc)\n",
    "                mcvaccuracy=sum(cvaccuracy)/len(cvaccuracy)\n",
    "\n",
    "                if(mcvaccuracy>bestacc):\n",
    "                    print(mcvaccuracy)\n",
    "                    bestacc=mcvaccuracy\n",
    "                    bestl=l\n",
    "                    bestdrop=d\n",
    "                    bestneuron=n\n",
    "                   \n",
    "    print('Best Accuracy on validation:',bestacc)\n",
    "    print('BestLearning:',bestl)\n",
    "    print('BestDrop:',bestdrop)\n",
    "    print('BestNeuron:',bestneuron)\n",
    "    tot=[]\n",
    "    print('LOOK HOW IT WORKS WITH TEST SET....')\n",
    "    opt=keras.optimizers.SGD(lr=bestl, momentum=0.0, decay=0.0, nesterov=False)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(bestneuron, input_shape=(2,), activation='sigmoid'))\n",
    "    model.add(Dropout(bestdrop))\n",
    "    model.add(Dense(bestneuron, activation='sigmoid'))\n",
    "    model.add(Dropout(bestdrop))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    model.fit(x_tvnew, y_tvnew, epochs=20, verbose=0,batch_size=10)\n",
    "    evaluation=model.evaluate(x=x_testnew, y=y_testnew, batch_size=10, verbose=0)   \n",
    "    acc=evaluation[1]\n",
    "    print('Accuracy on test set')\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
