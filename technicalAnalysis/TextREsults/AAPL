AAPL SVM senza pesi blanced e senza sampling
Working on... AAPL
Window: 2
[[  0 330]
 [  0 370]]
accuracy= 0.5285714285714286
Window: 4
[[  0 323]
 [  0 376]]
accuracy= 0.5379113018597997
Window: 6
[[  0 328]
 [  0 371]]
accuracy= 0.530758226037196
Window: 10
[[  0 324]
 [  0 374]]
accuracy= 0.5358166189111748
Window: 14
[[  0 325]
 [  0 372]]
accuracy= 0.533715925394548
Window: 18
[[  0 325]
 [  0 371]]
accuracy= 0.5330459770114943
Window: 22
[[  0 311]
 [  0 385]]
accuracy= 0.5531609195402298
Window: 26
[[  0 298]
 [  0 397]]
accuracy= 0.5712230215827339
Window: 32
[[  0 299]
 [  0 395]]
accuracy= 0.569164265129683
Window: 38
[[  0 296]
 [  0 396]]
accuracy= 0.5722543352601156
Window: 45
[[  0 296]
 [  0 395]]
accuracy= 0.5716353111432706
Window: 52
[[  0 311]
 [  0 379]]
accuracy= 0.5492753623188406
Window: 59
[[  0 309]
 [  0 379]]
accuracy= 0.5508720930232558
Window: 66
[[  0 319]
 [  0 368]]
accuracy= 0.5356622998544396
Window: 74
[[  0 342]
 [  0 343]]
accuracy= 0.5007299270072992
Window: 80
[[  0 342]
 [  0 342]]
accuracy= 0.5
Window: 87
[[  0 333]
 [  0 350]]
accuracy= 0.5124450951683748
Window: 96
[[  0 323]
 [  0 358]]
accuracy= 0.5256975036710719
Window: 104
[[  0 316]
 [  0 363]]
accuracy= 0.5346097201767305
Window: 112
[[  1 316]
 [  6 355]]
accuracy= 0.5250737463126843
Window: 125
[[  7 305]
 [  0 363]]
accuracy= 0.5481481481481482
Window: 140
[[  0 339]
 [  0 333]]
accuracy= 0.4955357142857143
Window: 160
[[  0 375]
 [  0 293]]
accuracy= 0.43862275449101795
Window: 175
[[  0 380]
 [  0 285]]
accuracy= 0.42857142857142855
Window: 190
[[  0 359]
 [  0 303]]
accuracy= 0.45770392749244715
Window: 205
[[  0 341]
 [  0 318]]
accuracy= 0.48254931714719274
Window: 220
[[  0 321]
 [  0 335]]
accuracy= 0.510670731707317
Window: 245
[[  0 260]
 [  0 391]]
accuracy= 0.6006144393241167
Window: 260
[[  0 253]
 [  0 395]]
accuracy= 0.6095679012345679
Window: 300
[[  0 257]
 [  0 383]]
accuracy= 0.5984375


AAPL KSVM senza pesi e senza sampling (sembra funzionare un filo meglio ma davvero poco)
Working on... AAPL
Window: 2
[[  0 331]
 [  0 370]]
accuracy= 0.5278174037089871
Window: 4
[[  0 325]
 [  0 376]]
accuracy= 0.536376604850214
Window: 6
[[  0 329]
 [  0 371]]
accuracy= 0.53
Window: 10
[[  0 324]
 [  0 375]]
accuracy= 0.5364806866952789
Window: 14
[[  0 325]
 [  0 374]]
accuracy= 0.5350500715307582
Window: 18
[[  0 325]
 [  0 373]]
accuracy= 0.5343839541547278
Window: 22
[[  0 311]
 [  0 386]]
accuracy= 0.5538020086083214
Window: 26
[[  0 298]
 [  0 398]]
accuracy= 0.5718390804597702
Window: 32
[[  0 299]
 [  0 396]]
accuracy= 0.5697841726618705
Window: 38
[[  0 296]
 [  0 398]]
accuracy= 0.5734870317002881
Window: 45
[[  0 296]
 [  0 396]]
accuracy= 0.5722543352601156
Window: 52
[[251  60]
 [207 173]]
accuracy= 0.613603473227207
Window: 59
[[  0 309]
 [  0 381]]
accuracy= 0.5521739130434783
Window: 66
[[  0 320]
 [  0 368]]
accuracy= 0.5348837209302325
Window: 74
[[  0 344]
 [  0 343]]
accuracy= 0.4992721979621543
Window: 80
[[266  77]
 [ 97 245]]
accuracy= 0.745985401459854
Window: 87
[[236  98]
 [ 93 257]]
accuracy= 0.7207602339181286
Window: 96
[[189 135]
 [ 83 275]]
accuracy= 0.6803519061583577
Window: 104
[[  0 317]
 [  8 356]]
accuracy= 0.5227606461086637
Window: 112
[[ 28 289]
 [ 14 348]]
accuracy= 0.5537555228276878
Window: 125
[[  0 312]
 [  0 364]]
accuracy= 0.5384615384615384
Window: 140
[[254  85]
 [ 89 245]]
accuracy= 0.7414561664190193
Window: 160
[[  0 376]
 [  0 293]]
accuracy= 0.43796711509715996
Window: 175
[[  0 381]
 [  0 285]]
accuracy= 0.42792792792792794
Window: 190
[[  0 359]
 [  0 304]]
accuracy= 0.45852187028657615
Window: 205
[[  0 341]
 [  0 319]]
accuracy= 0.48333333333333334
Window: 220
[[  0 321]
 [  0 336]]
accuracy= 0.5114155251141552
Window: 245
[[  0 260]
 [  0 392]]
accuracy= 0.6012269938650306
Window: 260
[[  0 253]
 [  0 396]]
accuracy= 0.6101694915254238
Window: 300
[[  0 257]
 [  0 384]]
accuracy= 0.5990639625585024

AAPL SVM con pesi inv prop alla classe w0=(#c1/#c0)*w1 (spesso si salta dal sempre positivo al sempre negativo)
Working on... AAPL
Window: 2
[[250   0]
 [274   0]]
accuracy= 0.4770992366412214
Window: 4
[[247   0]
 [277   0]]
accuracy= 0.4713740458015267
Window: 6
[[  0 251]
 [  0 273]]
accuracy= 0.5209923664122137
Window: 10
[[188  73]
 [172  90]]
accuracy= 0.5315487571701721
Window: 16
[[278   0]
 [244   0]]
accuracy= 0.5325670498084292
Window: 24
[[  7 260]
 [  7 246]]
accuracy= 0.48653846153846153
Window: 32
[[264   0]
 [254   0]]
accuracy= 0.5096525096525096
Window: 42
[[ 91 161]
 [135 129]]
accuracy= 0.4263565891472868
Window: 56
[[ 46 207]
 [111 150]]
accuracy= 0.38132295719844356
Window: 66
[[256   0]
 [256   0]]
accuracy= 0.5
Window: 87
[[  0 276]
 [  0 231]]
accuracy= 0.4556213017751479
Window: 100
[[279   0]
 [226   0]]
accuracy= 0.5524752475247525
Window: 112
[[285   0]
 [217   0]]
accuracy= 0.5677290836653387
Window: 125
[[  0 287]
 [  2 211]]
accuracy= 0.422
Window: 140
[[  0 291]
 [  0 206]]
accuracy= 0.41448692152917505
Window: 160
[[  0 297]
 [ 17 179]]
accuracy= 0.3630831643002028
Window: 175
[[  0 289]
 [  0 201]]
accuracy= 0.41020408163265304
Window: 190
[[263   0]
 [224   0]]
accuracy= 0.5400410677618069
Window: 205
[[  0 233]
 [  0 251]]
accuracy= 0.518595041322314
Window: 220
[[  0 206]
 [  0 275]]
accuracy= 0.5717255717255717
Window: 245
[[  0 140]
 [  0 336]]
accuracy= 0.7058823529411765
Window: 260
[[  0 128]
 [  0 345]]
accuracy= 0.7293868921775899
Window: 300
[[  0 145]
 [  0 320]]
accuracy= 0.6881720430107527
Window: 350
[[  0 110]
 [ 14 331]]
accuracy= 0.7274725274725274
Window: 400
[[  0 132]
 [  0 313]]
accuracy= 0.7033707865168539

AAPL SVM con oversampling (HO RIPORTATO APPELE PERCHE E' UNO DI QUELLI SUL QUALE L'OVERSAMPLING FUNZIONA PEGGIO)
Working on... AAPL
/home/andrea/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:32: RuntimeWarning: overflow encountered in reduce
  return umr_sum(a, axis, dtype, out, keepdims)
Window: 2
[[  0 324]
 [  0 346]]
F1,score 0.6811023622047243
Accuracy: 0.5164179104477612
Window: 4
[[  0 321]
 [  0 349]]
F1,score 0.6849852796859666
Accuracy: 0.5208955223880597
Window: 6
[[  0 320]
 [  0 349]]
F1,score 0.6856581532416504
Accuracy: 0.5216741405082213
Window: 10
[[  0 318]
 [  0 351]]
F1,score 0.6882352941176471
Accuracy: 0.5246636771300448
Window: 16
[[  0 330]
 [  0 337]]
F1,score 0.6713147410358566
Accuracy: 0.5052473763118441
Window: 24
[[  0 331]
 [  0 335]]
F1,score 0.6693306693306693
Accuracy: 0.503003003003003
Window: 32
[[  0 322]
 [  0 342]]
F1,score 0.679920477137177
Accuracy: 0.5150602409638554
Window: 42
[[  4 310]
 [  6 342]]
F1,score 0.6839999999999999
Accuracy: 0.5226586102719033
Window: 56
[[  0 319]
 [  2 338]]
F1,score 0.6780341023069206
Accuracy: 0.5128983308042488
Window: 66
[[  1 342]
 [  3 311]]
F1,score 0.6432264736297828
Accuracy: 0.4748858447488584
Window: 87
[[  1 339]
 [  1 312]]
F1,score 0.6473029045643153
Accuracy: 0.4793261868300153
Window: 100
[[ 41 292]
 [  9 309]]
F1,score 0.6724700761697497
Accuracy: 0.5376344086021505
Window: 112
[[  6 334]
 [  4 304]]
F1,score 0.6427061310782242
Accuracy: 0.4783950617283951
Window: 125
[[ 26 321]
 [ 18 281]]
F1,score 0.6237513873473918
Accuracy: 0.47523219814241485
Window: 140
[[  0 366]
 [  0 277]]
F1,score 0.6021739130434782
Accuracy: 0.4307931570762053
Window: 160
[[ 71 271]
 [ 39 258]]
F1,score 0.6246973365617433
Accuracy: 0.514866979655712
Window: 175
[[313   5]
 [267  51]]
F1,score 0.2727272727272727
Accuracy: 0.5723270440251572
Window: 190
[[273   0]
 [323  37]]
F1,score 0.18639798488664985
Accuracy: 0.48973143759873616
Window: 205
[[ 18 233]
 [ 39 340]]
F1,score 0.7142857142857144
Accuracy: 0.5682539682539682
Window: 220
[[230   0]
 [367  30]]
F1,score 0.14051522248243561
Accuracy: 0.41467304625199364
Window: 245
[[  0 219]
 [  0 403]]
F1,score 0.7863414634146342
Accuracy: 0.6479099678456591
Window: 260
[[193  10]
 [253 163]]
F1,score 0.5534804753820034
Accuracy: 0.5751211631663974
Window: 300
[[ 48 152]
 [ 30 381]]
F1,score 0.8072033898305084
Accuracy: 0.7021276595744681
Window: 350
[[ 47  95]
 [ 14 445]]
F1,score 0.8908908908908908
Accuracy: 0.8186356073211315
Window: 400
[[  0 134]
 [ 27 430]]
F1,score 0.842311459353575
Accuracy: 0.727580372250423

